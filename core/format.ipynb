{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c0b377-1fce-4b19-9e77-0cf81adaf0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('data/bodyfat_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4549e8-2b72-4df0-9ec5-5b0f668680bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>meanPrediction</th>\n",
       "      <th>medianPrediction</th>\n",
       "      <th>bfPredictions</th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>image_3</th>\n",
       "      <th>image_4</th>\n",
       "      <th>image_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leanest ive ever been. Never seen veins like t...</td>\n",
       "      <td>https://www.reddit.com/gallery/1b6k5jh</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let me know. 78kg :)</td>\n",
       "      <td>https://i.redd.it/4occeq9wdd2c1.jpg</td>\n",
       "      <td>9.80</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[9, 10, 10, 9, 11]</td>\n",
       "      <td>https://i.redd.it/4occeq9wdd2c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is my bf% I believe it’s around 13-14%</td>\n",
       "      <td>https://i.redd.it/lvfmowq0zhh91.jpg</td>\n",
       "      <td>14.33</td>\n",
       "      <td>13.5</td>\n",
       "      <td>[13, 19, 14, 14, 13, 13]</td>\n",
       "      <td>https://i.redd.it/lvfmowq0zhh91.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25F | 4'11\" | 107 lbs</td>\n",
       "      <td>https://www.reddit.com/gallery/1e30z2f</td>\n",
       "      <td>23.33</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[20, 26, 24]</td>\n",
       "      <td>https://preview.redd.it/25f-411-107-lbs-v0-4lm...</td>\n",
       "      <td>https://preview.redd.it/25f-411-107-lbs-v0-huc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bodyfat?</td>\n",
       "      <td>https://www.reddit.com/gallery/1ktwao9</td>\n",
       "      <td>17.80</td>\n",
       "      <td>18.0</td>\n",
       "      <td>[18, 16, 18, 15, 22]</td>\n",
       "      <td>https://preview.redd.it/8ekhv0d4xl2f1.jpg?widt...</td>\n",
       "      <td>https://preview.redd.it/rwkt50d4xl2f1.jpg?widt...</td>\n",
       "      <td>https://preview.redd.it/vau412d4xl2f1.jpg?widt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>[GMBF] 6'1 220LBS Any estimates appreciated!</td>\n",
       "      <td>https://i.redd.it/z543jfquva731.jpg</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[12]</td>\n",
       "      <td>https://i.redd.it/z543jfquva731.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>[GMBF] (M/22/6'2\"/195lbs)</td>\n",
       "      <td>https://i.imgur.com/PY44dK5.jpg</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.5</td>\n",
       "      <td>[11, 9, 10, 12]</td>\n",
       "      <td>https://i.imgur.com/PY44dK5.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>[GMBF] M/26/6'1/191lbs - down from 245lbs</td>\n",
       "      <td>https://i.imgur.com/pWGT7nV.jpg</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[15]</td>\n",
       "      <td>https://i.imgur.com/pWGT7nV.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>[GMBF] (M/26/5’10”/153lbs to 168lbs) What woul...</td>\n",
       "      <td>https://i.redd.it/lc2q2svumrt11.jpg</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[10, 14]</td>\n",
       "      <td>https://i.redd.it/lc2q2svumrt11.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Thoughts?</td>\n",
       "      <td>https://i.redd.it/3yube1tanu1f1.jpeg</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.5</td>\n",
       "      <td>[14, 13]</td>\n",
       "      <td>https://i.redd.it/3yube1tanu1f1.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Leanest ive ever been. Never seen veins like t...   \n",
       "1                                 Let me know. 78kg :)   \n",
       "2          What is my bf% I believe it’s around 13-14%   \n",
       "3                               25F | 4'11\" | 107 lbs    \n",
       "4                                             Bodyfat?   \n",
       "..                                                 ...   \n",
       "791       [GMBF] 6'1 220LBS Any estimates appreciated!   \n",
       "792                          [GMBF] (M/22/6'2\"/195lbs)   \n",
       "793          [GMBF] M/26/6'1/191lbs - down from 245lbs   \n",
       "794  [GMBF] (M/26/5’10”/153lbs to 168lbs) What woul...   \n",
       "795                                          Thoughts?   \n",
       "\n",
       "                                        url  meanPrediction  medianPrediction  \\\n",
       "0    https://www.reddit.com/gallery/1b6k5jh            8.00               8.0   \n",
       "1       https://i.redd.it/4occeq9wdd2c1.jpg            9.80              10.0   \n",
       "2       https://i.redd.it/lvfmowq0zhh91.jpg           14.33              13.5   \n",
       "3    https://www.reddit.com/gallery/1e30z2f           23.33              24.0   \n",
       "4    https://www.reddit.com/gallery/1ktwao9           17.80              18.0   \n",
       "..                                      ...             ...               ...   \n",
       "791     https://i.redd.it/z543jfquva731.jpg           12.00              12.0   \n",
       "792         https://i.imgur.com/PY44dK5.jpg           10.50              10.5   \n",
       "793         https://i.imgur.com/pWGT7nV.jpg           15.00              15.0   \n",
       "794     https://i.redd.it/lc2q2svumrt11.jpg           12.00              12.0   \n",
       "795    https://i.redd.it/3yube1tanu1f1.jpeg           13.50              13.5   \n",
       "\n",
       "                bfPredictions  \\\n",
       "0                         [8]   \n",
       "1          [9, 10, 10, 9, 11]   \n",
       "2    [13, 19, 14, 14, 13, 13]   \n",
       "3                [20, 26, 24]   \n",
       "4        [18, 16, 18, 15, 22]   \n",
       "..                        ...   \n",
       "791                      [12]   \n",
       "792           [11, 9, 10, 12]   \n",
       "793                      [15]   \n",
       "794                  [10, 14]   \n",
       "795                  [14, 13]   \n",
       "\n",
       "                                               image_1  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                  https://i.redd.it/4occeq9wdd2c1.jpg   \n",
       "2                  https://i.redd.it/lvfmowq0zhh91.jpg   \n",
       "3    https://preview.redd.it/25f-411-107-lbs-v0-4lm...   \n",
       "4    https://preview.redd.it/8ekhv0d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "791                https://i.redd.it/z543jfquva731.jpg   \n",
       "792                    https://i.imgur.com/PY44dK5.jpg   \n",
       "793                    https://i.imgur.com/pWGT7nV.jpg   \n",
       "794                https://i.redd.it/lc2q2svumrt11.jpg   \n",
       "795               https://i.redd.it/3yube1tanu1f1.jpeg   \n",
       "\n",
       "                                               image_2  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    https://preview.redd.it/25f-411-107-lbs-v0-huc...   \n",
       "4    https://preview.redd.it/rwkt50d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "791                                                NaN   \n",
       "792                                                NaN   \n",
       "793                                                NaN   \n",
       "794                                                NaN   \n",
       "795                                                NaN   \n",
       "\n",
       "                                               image_3  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    https://preview.redd.it/vau412d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "791                                                NaN   \n",
       "792                                                NaN   \n",
       "793                                                NaN   \n",
       "794                                                NaN   \n",
       "795                                                NaN   \n",
       "\n",
       "                                               image_4  image_5  \n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...      NaN  \n",
       "1                                                  NaN      NaN  \n",
       "2                                                  NaN      NaN  \n",
       "3                                                  NaN      NaN  \n",
       "4                                                  NaN      NaN  \n",
       "..                                                 ...      ...  \n",
       "791                                                NaN      NaN  \n",
       "792                                                NaN      NaN  \n",
       "793                                                NaN      NaN  \n",
       "794                                                NaN      NaN  \n",
       "795                                                NaN      NaN  \n",
       "\n",
       "[796 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865e79e0-2e1c-4672-8a10-969a55f38752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import requests\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "\n",
    "def download_and_crop_images(df, output_dir=\"images\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_cols = [f\"image_{i}\" for i in range(1, 6)]\n",
    "\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "    def crop_upper_body_cv2(img):\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(img_rgb)\n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            h, w, _ = img.shape\n",
    "\n",
    "            xs = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * w,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * w]\n",
    "\n",
    "            ys = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * h,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * h]\n",
    "\n",
    "            xmin, xmax = int(min(xs)), int(max(xs))\n",
    "            ymin, ymax = int(min(ys)), int(max(ys))\n",
    "\n",
    "            # Add padding\n",
    "            pad_x = 20\n",
    "            pad_y = 20\n",
    "            xmin = max(xmin - pad_x, 0)\n",
    "            xmax = min(xmax + pad_x, w)\n",
    "            ymin = max(ymin - pad_y, 0)\n",
    "            ymax = min(ymax + pad_y, h)\n",
    "\n",
    "            # Expand box\n",
    "            expand = int((xmax - xmin) * 0.5)\n",
    "            xmin = max(xmin - expand, 0)\n",
    "            xmax = min(xmax + expand, w)\n",
    "\n",
    "            cropped = img[ymin:ymax, xmin:xmax]\n",
    "            return cropped\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    seen_urls = set()\n",
    "    image_count = 0\n",
    "    failed = 0\n",
    "\n",
    "    x = 0\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        for col in image_cols:\n",
    "            x+=1\n",
    "            url = row.get(col)\n",
    "            if isinstance(url, str) and url.startswith(\"http\") and url not in seen_urls:\n",
    "                try:\n",
    "                    response = requests.get(url, timeout=10)\n",
    "                    if response.status_code == 200:\n",
    "                        img_arr = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "                        img = cv2.imdecode(img_arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "                        if img is None:\n",
    "                            raise ValueError(\"Downloaded image could not be decoded\")\n",
    "\n",
    "                        cropped = crop_upper_body_cv2(img)\n",
    "                        final_img = cropped if cropped is not None else img\n",
    "                        final_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)\n",
    "                        pil_img = Image.fromarray(final_img)\n",
    "\n",
    "                        file_ext = url.split('.')[-1].split('?')[0]\n",
    "                        file_name = f\"{idx}_{col}.{file_ext}\"\n",
    "                        file_path = os.path.join(output_dir, file_name)\n",
    "                        pil_img.save(file_path)\n",
    "\n",
    "                        seen_urls.add(url)\n",
    "                        image_count += 1\n",
    "                    else:\n",
    "                        failed += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading or processing {url}: {e}\")\n",
    "                    failed += 1\n",
    "\n",
    "    print(f\"\\n✔️ Downloaded and cropped {image_count} unique images to '{output_dir}/'\")\n",
    "    print(f\"{x} images\")\n",
    "    if failed:\n",
    "        print(f\"⚠️ {failed} images failed to download or process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9876b101-99d9-44d3-9edd-4db973cafa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_csv(df, output_csv=\"image_labels.csv\", label_col=\"meanPrediction\", image_prefix=\"image_\"):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    image_cols = [col for col in df.columns if col.startswith(image_prefix)]\n",
    "    records = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        label = row[label_col]\n",
    "\n",
    "        for col in image_cols:\n",
    "            url = row.get(col)\n",
    "\n",
    "            # Debug url at idx 176 for each image col\n",
    "            if idx == 175:\n",
    "                print(f\"DEBUG idx={idx} col={col} url={url}\")\n",
    "\n",
    "            if isinstance(url, str) and url.startswith(\"http\"):\n",
    "                ext = url.split('.')[-1].split('?')[0].lower()\n",
    "                ext = ext if ext in ['jpg', 'jpeg', 'png', 'webp'] else 'jpg'\n",
    "                filename = f\"{idx}_{col}.{ext}\"\n",
    "\n",
    "                # Debug filename and label for idx 176\n",
    "                if idx == 176:\n",
    "                    print(f\"DEBUG idx={idx} filename={filename} label={label}\")\n",
    "\n",
    "                records.append({\"filename\": filename, \"target\": label})\n",
    "\n",
    "    df_out = pd.DataFrame(records)\n",
    "    df_out.to_csv(output_csv, index=False)\n",
    "    print(f\"Created {output_csv} with {len(df_out)} labeled images\")\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940a2b9a-56aa-4b9b-a965-c82eab37222b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_and_crop_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdownload_and_crop_images\u001b[49m(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'download_and_crop_images' is not defined"
     ]
    }
   ],
   "source": [
    "download_and_crop_images(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8966a08-ea3d-4287-8194-cc288e8a09c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG idx=175 col=image_1 url=https://preview.redd.it/6-172-lbs-curious-about-bf-after-losing-280-lbs-v0-jz3w2jzvq96e1.jpg?width=640&crop=smart&auto=webp&s=27969c92649102cfd44ee367f269f92ee7b69131\n",
      "DEBUG idx=175 col=image_2 url=https://preview.redd.it/6-172-lbs-curious-about-bf-after-losing-280-lbs-v0-cib4qizvq96e1.jpg?width=640&crop=smart&auto=webp&s=059bc43b751154ec72149fce338e4169173dfbec\n",
      "DEBUG idx=175 col=image_3 url=https://preview.redd.it/6-172-lbs-curious-about-bf-after-losing-280-lbs-v0-3b9oyizvq96e1.jpg?width=640&crop=smart&auto=webp&s=1d52db25d8c6961213364ced376cc4afc75bedce\n",
      "DEBUG idx=175 col=image_4 url=https://preview.redd.it/6-172-lbs-curious-about-bf-after-losing-280-lbs-v0-6b31hjzvq96e1.jpg?width=640&crop=smart&auto=webp&s=4c9720f857a9a71edc268d1aab4d32554f1c646a\n",
      "DEBUG idx=175 col=image_5 url=nan\n",
      "DEBUG idx=176 filename=176_image_1.jpg label=15.67\n",
      "Created data/image_labels.csv with 1580 labeled images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_image_1.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_image_2.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_image_3.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_image_4.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_image_1.jpg</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>791_image_1.jpg</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>792_image_1.jpg</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>793_image_1.jpg</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>794_image_1.jpg</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>795_image_1.jpeg</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1580 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  target\n",
       "0        0_image_1.jpg     8.0\n",
       "1        0_image_2.jpg     8.0\n",
       "2        0_image_3.jpg     8.0\n",
       "3        0_image_4.jpg     8.0\n",
       "4        1_image_1.jpg     9.8\n",
       "...                ...     ...\n",
       "1575   791_image_1.jpg    12.0\n",
       "1576   792_image_1.jpg    10.5\n",
       "1577   793_image_1.jpg    15.0\n",
       "1578   794_image_1.jpg    12.0\n",
       "1579  795_image_1.jpeg    13.5\n",
       "\n",
       "[1580 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = create_regression_csv(df, output_csv=\"data/image_labels.csv\") \n",
    "df_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9f8e09-22b7-472a-bba3-0d7c297279d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "failed = verify_images(get_image_files(Path('images')))\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eccfd31-348b-4d5a-b275-d0004d7b6400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: No NaN values found in 'target' column.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "initial_nan_labels_count = df_labels['target'].isna().sum()\n",
    "if initial_nan_labels_count > 0:\n",
    "    print(f\"DEBUG: Found {initial_nan_labels_count} NaN values in 'target' column. Dropping rows with NaN targets.\")\n",
    "    df_labels.dropna(subset=['target'], inplace=True)\n",
    "else:\n",
    "    print(\"DEBUG: No NaN values found in 'target' column.\")\n",
    "\n",
    "train_df, valid_df = train_test_split(df_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df.to_csv(\"data/train_set.csv\")\n",
    "valid_df.to_csv(\"data/valid_set.csv\")\n",
    "\n",
    "train_label_dict = dict(zip(train_df['filename'], train_df['target']))\n",
    "valid_label_dict = dict(zip(valid_df['filename'], valid_df['target']))\n",
    "all_label_dict = {**train_label_dict, **valid_label_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbf9ad-3789-4648-a3b3-742dcc8f6bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
