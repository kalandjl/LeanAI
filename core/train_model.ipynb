{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch, numpy as np, pandas as pd\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_image_1.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_image_2.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_image_3.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_image_4.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_image_1.jpg</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>791_image_1.jpg</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>792_image_1.jpg</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>793_image_1.jpg</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>794_image_1.jpg</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>795_image_1.jpeg</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1580 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  target\n",
       "0        0_image_1.jpg     8.0\n",
       "1        0_image_2.jpg     8.0\n",
       "2        0_image_3.jpg     8.0\n",
       "3        0_image_4.jpg     8.0\n",
       "4        1_image_1.jpg     9.8\n",
       "...                ...     ...\n",
       "1575   791_image_1.jpg    12.0\n",
       "1576   792_image_1.jpg    10.5\n",
       "1577   793_image_1.jpg    15.0\n",
       "1578   794_image_1.jpg    12.0\n",
       "1579  795_image_1.jpeg    13.5\n",
       "\n",
       "[1580 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(Path('data/image_labels.csv'))\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv(\"data/train_set.csv\")\n",
    "valid_df = pd.read_csv(\"data/valid_set.csv\")\n",
    "\n",
    "train_label_dict = dict(zip(train_df['filename'], train_df['target']))\n",
    "valid_label_dict = dict(zip(valid_df['filename'], valid_df['target']))\n",
    "all_label_dict = {**train_label_dict, **valid_label_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Train labels: 1264 | Valid labels: 316\n",
      "DEBUG: Image path set to: images\n",
      "DEBUG: Total image files found by get_image_files: 2259\n",
      "DEBUG: Processable image files (with matching labels): 1575\n"
     ]
    }
   ],
   "source": [
    "print(f\"DEBUG: Train labels: {len(train_label_dict)} | Valid labels: {len(valid_label_dict)}\")\n",
    "\n",
    "# Get all image files\n",
    "path = Path('images')\n",
    "print(f\"DEBUG: Image path set to: {path}\")\n",
    "\n",
    "all_image_files = get_image_files(path)\n",
    "print(f\"DEBUG: Total image files found by get_image_files: {len(all_image_files)}\")\n",
    "\n",
    "# Filter image files to only those with matching labels\n",
    "processable_image_files = [f for f in all_image_files if f.name in all_label_dict]\n",
    "print(f\"DEBUG: Processable image files (with matching labels): {len(processable_image_files)}\")\n",
    "\n",
    "# Safety check\n",
    "if len(processable_image_files) == 0:\n",
    "    print(\"CERROR: No processable image files found (no images match labels or vice-versa).\")\n",
    "    if all_image_files and all_label_dict:\n",
    "        print(f\"  Sample image file: {all_image_files[0].name}\")\n",
    "        print(f\"  Sample label key: {next(iter(all_label_dict.keys()))}\")\n",
    "        if all_image_files[0].name not in all_label_dict and all_image_files[0].name.split('.')[0] in [k.split('.')[0] for k in all_label_dict.keys()]:\n",
    "            print(\" Filename extensions might differ between image files and label keys.\")\n",
    "    raise ValueError(\"Cannot create DataLoaders: No matching image files and labels.\")\n",
    "\n",
    "# Helper function to get label\n",
    "def get_y_func(fn):\n",
    "    key = fn.name\n",
    "    if key not in all_label_dict:\n",
    "        print(f\"DEBUG ERROR: Label not found for: {key} during get_y_func call. This should not happen if pre-filtered.\")\n",
    "        raise ValueError(f\"Label not found for: {key}\")\n",
    "    return all_label_dict[key]\n",
    "\n",
    "# Generate index lists for DataBlock IndexSplitter\n",
    "filename_to_index = {f.name: i for i, f in enumerate(processable_image_files)}\n",
    "valid_idxs = [filename_to_index[fname] for fname in valid_df['filename'] if fname in filename_to_index]\n",
    "splitter = IndexSplitter(valid_idxs)\n",
    "\n",
    "def convert_to_rgb(img):\n",
    "    return img.convert('RGB')\n",
    "\n",
    "# Use your existing setup for labels, image files, get_y_func, splitter, etc.\n",
    "\n",
    "def get_datablock_variant(variant:int):\n",
    "    \"\"\"\n",
    "    Returns a DataBlock with different augmentations depending on variant 1, 2, or 3.\n",
    "    \"\"\"\n",
    "    # Base parameters from your original\n",
    "    get_items_func = lambda _: processable_image_files\n",
    "    splitter_func = splitter\n",
    "    get_y_func_func = get_y_func\n",
    "    item_tfms_base = RandomResizedCrop(224)\n",
    "\n",
    "    # Different batch transforms per variant\n",
    "    if variant == 1:\n",
    "        batch_tfms_variant = aug_transforms(\n",
    "            do_flip=False,\n",
    "            max_rotate=2,\n",
    "            max_zoom=1.05,\n",
    "            max_lighting=0.1,\n",
    "            max_warp=0.,\n",
    "            p_affine=0.3,\n",
    "            p_lighting=0.3\n",
    "        )\n",
    "    elif variant == 2:\n",
    "        batch_tfms_variant = aug_transforms(\n",
    "            do_flip=True,\n",
    "            max_rotate=10,\n",
    "            max_zoom=1.2,\n",
    "            max_lighting=0.2,\n",
    "            max_warp=0.2,\n",
    "            p_affine=0.5,\n",
    "            p_lighting=0.5\n",
    "        )\n",
    "    elif variant == 3:\n",
    "        batch_tfms_variant = aug_transforms(\n",
    "            do_flip=True,\n",
    "            max_rotate=20,\n",
    "            max_zoom=1.3,\n",
    "            max_lighting=0.3,\n",
    "            max_warp=0.3,\n",
    "            p_affine=0.7,\n",
    "            p_lighting=0.7\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"variant must be 1, 2, or 3\")\n",
    "\n",
    "    return DataBlock(\n",
    "        blocks=(ImageBlock, RegressionBlock),\n",
    "        get_items=get_items_func,\n",
    "        splitter=splitter_func,\n",
    "        get_y=get_y_func_func,\n",
    "        item_tfms=item_tfms_base,\n",
    "        batch_tfms=batch_tfms_variant,\n",
    "        n_inp=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls1 = get_datablock_variant(1).dataloaders(path, bs=16)\n",
    "dls2 = get_datablock_variant(2).dataloaders(path, bs=16)\n",
    "dls3 = get_datablock_variant(3).dataloaders(path, bs=16)\n",
    "\n",
    "dls_list = [dls1, dls2, dls3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        abs_error = torch.abs(input - target)\n",
    "        quadratic = torch.minimum(abs_error, torch.tensor(self.delta))\n",
    "        linear = abs_error - quadratic\n",
    "        loss = 0.5 * quadratic**2 + self.delta * linear\n",
    "        return loss.mean()\n",
    "\n",
    "def mae(preds, targs):\n",
    "    # Ensure target shape matches preds\n",
    "    if targs.ndim == 1:\n",
    "        targs = targs.unsqueeze(1)\n",
    "    return nn.L1Loss()(preds, targs)\n",
    "\n",
    "class RMCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        error_cubed = torch.abs(input - target) ** 3\n",
    "        mean_cubed_error = torch.mean(error_cubed)\n",
    "        loss = torch.pow(mean_cubed_error, 1/3)\n",
    "        return loss  # must be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from fastai.vision.all import *\n",
    "\n",
    "model_name='efficientnet_b3'\n",
    "\n",
    "# Create model with correct input size\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "# Replace the classification head with a regression head\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "\n",
    "# Create learner with the pre-configured model\n",
    "learn = Learner(get_datablock_variant(1), model, metrics=[rmse, mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.recorder.values[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have a working model! For example, it predicts this picture at 13% bodyfat (not so far off in my opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bf,_,probs = learn.predict(PILImage.create('images/248_image_2.jpg'))\n",
    "#print(f\"Bodyfat prediction: {probs[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_tag=\"\"\n",
    "path = f\"model/{model_name}{folder_tag}/model.pkl\"\n",
    "#learn.export(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Debugging resnet50d ---\n",
      "Original model created: resnet50d\n",
      "  Replaced 'fc' head. New head: Linear(in_features=2048, out_features=1, bias=True)\n",
      "  SUCCESS: resnet50d head replaced and output shape is torch.Size([1, 1]) (correct for regression).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging mobilenetv3_large_100 ---\n",
      "Original model created: mobilenetv3_large_100\n",
      "  Replaced 'classifier' head. New head: Linear(in_features=1280, out_features=1, bias=True)\n",
      "  SUCCESS: mobilenetv3_large_100 head replaced and output shape is torch.Size([1, 1]) (correct for regression).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging densenet121 ---\n",
      "Original model created: densenet121\n",
      "  Replaced 'classifier' head. New head: Linear(in_features=1024, out_features=1, bias=True)\n",
      "  SUCCESS: densenet121 head replaced and output shape is torch.Size([1, 1]) (correct for regression).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging convnext_tiny ---\n",
      "Original model created: convnext_tiny\n",
      "  Specific replacement for convnext_tiny: model.head.fc. New head: Linear(in_features=768, out_features=1, bias=True)\n",
      "  SUCCESS: convnext_tiny head replaced and output shape is torch.Size([1, 1]) (correct for regression).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging convnext_nano ---\n",
      "Original model created: convnext_nano\n",
      "  Specific replacement for convnext_nano: model.head.fc. New head: Linear(in_features=640, out_features=1, bias=True)\n",
      "  SUCCESS: convnext_nano head replaced and output shape is torch.Size([1, 1]) (correct for regression).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging regnety_040 ---\n",
      "Original model created: regnety_040\n",
      "  Specific replacement for regnety_040: model.head. New head: Linear(in_features=1088, out_features=1, bias=True)\n",
      "  ERROR debugging regnety_040: mat1 and mat2 shapes cannot be multiplied (7616x7 and 1088x1)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging coatnet_0_224 ---\n",
      "Original model created: coatnet_0_224\n",
      "  ERROR debugging coatnet_0_224: Head replacement not implemented for coatnet_0_224 with generic strategies.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging ghostnet_100 ---\n",
      "Original model created: ghostnet_100\n",
      "  Replaced 'classifier' head. New head: Linear(in_features=1280, out_features=1, bias=True)\n",
      "  SUCCESS: ghostnet_100 head replaced and output shape is torch.Size([1, 1]) (correct for regression).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging vit_base_patch16_224 ---\n",
      "Original model created: vit_base_patch16_224\n",
      "  Replaced 'head' (Linear) head. New head: Linear(in_features=768, out_features=1, bias=True)\n",
      "  SUCCESS: vit_base_patch16_224 head replaced and output shape is torch.Size([1, 1]) (correct for regression).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging deit_base_patch16_224 ---\n",
      "Original model created: deit_base_patch16_224\n",
      "  Replaced 'head' (Linear) head. New head: Linear(in_features=768, out_features=1, bias=True)\n",
      "  SUCCESS: deit_base_patch16_224 head replaced and output shape is torch.Size([1, 1]) (correct for regression).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging swin_tiny_patch4_window7_224 ---\n",
      "Original model created: swin_tiny_patch4_window7_224\n",
      "  Specific sequential replacement for swin_tiny_patch4_window7_224. New head: Sequential(\n",
      "  (0): Identity()\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n",
      "  ERROR debugging swin_tiny_patch4_window7_224: mat1 and mat2 shapes cannot be multiplied (1x37632 and 768x1)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging crossvit_tiny_240 ---\n",
      "Original model created: crossvit_tiny_240\n",
      "  ERROR debugging crossvit_tiny_240: 'ModuleList' object has no attribute 'norm'\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging maxvit_tiny_rw_224 ---\n",
      "Original model created: maxvit_tiny_rw_224\n",
      "  ERROR debugging maxvit_tiny_rw_224: 'ClassifierHead' object is not subscriptable\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging hiera_tiny_224 ---\n",
      "Original model created: hiera_tiny_224\n",
      "  Specific sequential replacement for hiera_tiny_224. New head: Sequential(\n",
      "  (0): Identity()\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n",
      "  ERROR debugging hiera_tiny_224: mat1 and mat2 shapes cannot be multiplied (1x37632 and 768x1)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging mambaout_tiny ---\n",
      "Original model created: mambaout_tiny\n",
      "  WARNING: mambaout_tiny head structure is complex. Requires manual inspection.\n",
      "  ERROR debugging mambaout_tiny: Complex head for mambaout_tiny, manual debug needed.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging mobileone_s1 ---\n",
      "Original model created: mobileone_s1\n",
      "  ERROR debugging mobileone_s1: Head replacement not implemented for mobileone_s1 with generic strategies.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Debugging efficientformerv2_s0 ---\n",
      "Original model created: efficientformerv2_s0\n",
      "  Replaced 'head' (Linear) head. New head: Linear(in_features=176, out_features=1, bias=True)\n",
      "  WARNING: efficientformerv2_s0 head replaced but output shape is torch.Size([1, 1000]) (expected [1,1]).\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from fastai.vision.all import * # You'll need this for ImageBlock, RegressionBlock if you want to fully simulate\n",
    "\n",
    "def debug_model_head_replacement(model_name):\n",
    "    print(f\"--- Debugging {model_name} ---\")\n",
    "    try:\n",
    "        # Step 1: Create the model\n",
    "        if model_name == 'coatnet_0_224':\n",
    "            # Special case for coatnet_0_224, as it doesn't have pretrained weights\n",
    "            model = timm.create_model(model_name, pretrained=False, num_classes=1)\n",
    "        else:\n",
    "            model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "        print(f\"Original model created: {model_name}\")\n",
    "        # print(\"Original model architecture (snippet of end):\")\n",
    "        # # Print last few layers for inspection\n",
    "        # for name, module in model.named_children():\n",
    "        #     if name in ['fc', 'classifier', 'head', 'stages', 'blocks', 'norm', 'act']: # common final layers/blocks\n",
    "        #         print(f\"  {name}: {module}\")\n",
    "\n",
    "\n",
    "        # Step 2: Attempt to replace the head using your logic\n",
    "        original_head = None\n",
    "        if hasattr(model, 'fc'):\n",
    "            original_head = model.fc\n",
    "            model.fc = nn.Linear(original_head.in_features, 1)\n",
    "            print(f\"  Replaced 'fc' head. New head: {model.fc}\")\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            original_head = model.classifier\n",
    "            model.classifier = nn.Linear(original_head.in_features, 1)\n",
    "            print(f\"  Replaced 'classifier' head. New head: {model.classifier}\")\n",
    "        elif hasattr(model, 'head'):\n",
    "            # This 'head' could be a Module, a Sequential, or even a different type\n",
    "            # You need to check its type to know how to replace it\n",
    "            if isinstance(model.head, nn.Linear): # if head is already a linear layer\n",
    "                original_head = model.head\n",
    "                model.head = nn.Linear(original_head.in_features, 1)\n",
    "                print(f\"  Replaced 'head' (Linear) head. New head: {model.head}\")\n",
    "            elif isinstance(model.head, nn.Sequential) and hasattr(model.head[-1], 'in_features'): # if last layer in sequential is linear\n",
    "                original_head = model.head[-1]\n",
    "                model.head[-1] = nn.Linear(original_head.in_features, 1)\n",
    "                print(f\"  Replaced last layer of 'head' (Sequential) head. New head: {model.head[-1]}\")\n",
    "            # --- Specific model adjustments start here ---\n",
    "            # You'll need to add specific conditions based on your inspection\n",
    "            elif model_name == 'convnext_tiny' or model_name == 'convnext_nano':\n",
    "                original_head = model.head.fc # ConvNeXt has a head.fc\n",
    "                model.head.fc = nn.Linear(original_head.in_features, 1)\n",
    "                print(f\"  Specific replacement for {model_name}: model.head.fc. New head: {model.head.fc}\")\n",
    "            elif model_name == 'regnety_040':\n",
    "                original_head = model.head # RegNet's head is directly a Linear layer\n",
    "                model.head = nn.Linear(original_head.in_features, 1)\n",
    "                print(f\"  Specific replacement for {model_name}: model.head. New head: {model.head}\")\n",
    "            elif model_name.startswith('swin_') or model_name.startswith('hiera_') or model_name.startswith('efficientformerv2_s0'):\n",
    "                # These models often require pooling before the final linear layer\n",
    "                # You might need to get the feature dimension differently if .num_features isn't available or accurate\n",
    "                try:\n",
    "                    num_features = model.num_features # Common for ViT-like models\n",
    "                except AttributeError:\n",
    "                    # Fallback for models that don't have .num_features\n",
    "                    # This is a rough estimation, you might need to run a dummy input to truly check\n",
    "                    dummy_input = torch.randn(1, 3, 224, 224)\n",
    "                    features = model.forward_features(dummy_input)\n",
    "                    num_features = features.shape[1] # Assumes (Batch, Features, H, W) -> (Batch, Features) after pooling\n",
    "                    if features.ndim > 2: # if it's still spatial\n",
    "                        print(f\"Warning: Features for {model_name} are spatial after forward_features. Assuming AdaptiveAvgPool2d.\")\n",
    "                        num_features = features.shape[1] * features.shape[2] * features.shape[3] # Fallback, assumes you flatten later\n",
    "\n",
    "                model.head = nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1) if model.head.in_features is None else nn.Identity(), # Add pooling if needed\n",
    "                    nn.Flatten(), # Ensure it's flattened\n",
    "                    nn.Linear(num_features, 1)\n",
    "                )\n",
    "                print(f\"  Specific sequential replacement for {model_name}. New head: {model.head}\")\n",
    "            elif model_name == 'crossvit_tiny_240':\n",
    "                # CrossViT's head is a ModuleList, need to access its last element\n",
    "                original_head = model.head.norm # Or model.head.mlp, inspect carefully\n",
    "                model.head.mlp = nn.Linear(original_head.in_features, 1) # This is an example, depends on inspection\n",
    "                print(f\"  Specific replacement for {model_name}: model.head.mlp. New head: {model.head.mlp}\")\n",
    "            elif model_name == 'maxvit_tiny_rw_224':\n",
    "                # MaxViT has a head which is a Sequential containing a Linear layer\n",
    "                original_head = model.head[2] # Example, you need to verify the index\n",
    "                model.head[2] = nn.Linear(original_head.in_features, 1)\n",
    "                print(f\"  Specific replacement for {model_name}: model.head[2]. New head: {model.head[2]}\")\n",
    "            elif model_name == 'mambaout_tiny':\n",
    "                # Mamba models might have a very specific head structure.\n",
    "                # You might need to examine its forward pass carefully.\n",
    "                # A common pattern is `model.norm_head` and `model.head`\n",
    "                if hasattr(model, 'head') and isinstance(model.head, nn.Linear):\n",
    "                    original_head = model.head\n",
    "                    model.head = nn.Linear(original_head.in_features, 1)\n",
    "                    print(f\"  Specific replacement for {model_name}: model.head (Linear). New head: {model.head}\")\n",
    "                else:\n",
    "                    print(f\"  WARNING: {model_name} head structure is complex. Requires manual inspection.\")\n",
    "                    # Fallback to general strategy or skip\n",
    "                    raise NotImplementedError(f\"Complex head for {model_name}, manual debug needed.\")\n",
    "\n",
    "            else: # Fallback to general strategy if none of the above match\n",
    "                raise NotImplementedError(f\"Head replacement not implemented for {model_name} with generic strategies.\")\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Could not find a standard head (fc, classifier, head) for {model_name}\")\n",
    "\n",
    "        # Step 3: Test with a dummy input\n",
    "        dummy_input = torch.randn(1, 3, 224, 224) # Assuming 224x224 input images\n",
    "        output = model(dummy_input)\n",
    "\n",
    "        if output.shape == torch.Size([1, 1]):\n",
    "            print(f\"  SUCCESS: {model_name} head replaced and output shape is {output.shape} (correct for regression).\")\n",
    "        else:\n",
    "            print(f\"  WARNING: {model_name} head replaced but output shape is {output.shape} (expected [1,1]).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR debugging {model_name}: {e}\")\n",
    "    print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# List of models to test\n",
    "all_models = [\n",
    "    'resnet50d',\n",
    "    'mobilenetv3_large_100',\n",
    "    'densenet121',\n",
    "    'convnext_tiny',\n",
    "    'convnext_nano',\n",
    "    'regnety_040',\n",
    "    'coatnet_0_224', # Special case for pretrained=False\n",
    "    'ghostnet_100',\n",
    "    'vit_base_patch16_224',\n",
    "    'deit_base_patch16_224',\n",
    "    'swin_tiny_patch4_window7_224',\n",
    "    'crossvit_tiny_240',\n",
    "    'maxvit_tiny_rw_224',\n",
    "    'hiera_tiny_224',\n",
    "    'mambaout_tiny',\n",
    "    'mobileone_s1',\n",
    "    'efficientformerv2_s0'\n",
    "]\n",
    "\n",
    "# Run the debugger for each model\n",
    "for model_name in all_models:\n",
    "    debug_model_head_replacement(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch, numpy as np, pandas as pd\n",
    "from fastai.vision.all import *\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import random \n",
    "\n",
    "def mae(preds, targs):\n",
    "    if targs.ndim == 1:\n",
    "        targs = targs.unsqueeze(1)\n",
    "    return nn.L1Loss()(preds, targs)\n",
    "\n",
    "def rmse(preds, targs):\n",
    "    # This assumes targs might be 1D, so unsqueeze for consistency if needed\n",
    "    if targs.ndim == 1:\n",
    "        targs = targs.unsqueeze(1)\n",
    "    return torch.sqrt(torch.mean((preds - targs)**2))\n",
    "\n",
    "\n",
    "# --- Your fine_tune_models function with enhanced head replacement ---\n",
    "def fine_tune_models(models=None, epochs=3, loss_func=None):\n",
    "    \n",
    "    metrics = [mae, rmse] # Using your defined mae and fastai's rmse\n",
    "    path = Path('images')\n",
    "\n",
    "    if models is None:\n",
    "        models = [\n",
    "            'resnet50d',                     # Variant of ResNet50 with minor improvements\n",
    "            'mobilenetv3_large_100',         # Good performer (MobileNet family)\n",
    "            'densenet121',                   # Dense connections, distinct feature learning\n",
    "            'convnext_tiny',                 # Modern pure CNN with Transformer influences\n",
    "            'convnext_nano',                 # Smaller, efficient ConvNeXt\n",
    "            'regnety_040',                   # Systematically designed CNN (RegNet family)\n",
    "            'coatnet_0_224',                 # Hybrid CNN-Transformer\n",
    "            'ghostnet_100',                  # Efficient, mobile-friendly CNN\n",
    "            'vit_base_patch16_224',          # Core Vision Transformer\n",
    "            'deit_base_patch16_224',         # Distillation-enhanced ViT\n",
    "            'swin_tiny_patch4_window7_224',  # Hierarchical Transformer, multi-scale\n",
    "            'crossvit_tiny_240',             # Cross-attention, different attention mechanism\n",
    "            'maxvit_tiny_rw_224',            # Newer hybrid, effective convolution-attention mix\n",
    "            'hiera_tiny_224',                # Recent, state-of-the-art hierarchical Transformer\n",
    "            'mambaout_tiny',                 # Novel architecture based on Mamba, distinct modeling\n",
    "            'mobileone_s1',                  # Designed for efficient inference, potentially robust features\n",
    "            'efficientformerv2_s0'           # Very efficient and modern hybrid architecture\n",
    "        ]\n",
    "\n",
    "    if loss_func is None:\n",
    "        loss_func = MSELossFlat()\n",
    "    if metrics is None:\n",
    "        metrics = [mae]\n",
    "\n",
    "    learners = {} # Initialize learners dictionary\n",
    "\n",
    "    for model_name in models:\n",
    "        db_variant = random.randint(1, 3)\n",
    "        chosen_db = get_datablock_variant(db_variant)\n",
    "        chosen_dls = chosen_db.dataloaders(path, bs=16)\n",
    "\n",
    "        print(f\"Setting up and fine-tuning {model_name}...\")\n",
    "        print(f\"Datablock Variant: {db_variant}...\")\n",
    "\n",
    "        try:\n",
    "            # Step 1: Create the model, handling pretrained=False for coatnet_0_224\n",
    "            if model_name == 'coatnet_0_224':\n",
    "                model = timm.create_model(model_name, pretrained=False)\n",
    "            elif model_name == 'efficientformerv2_s0':\n",
    "                 # EfficientFormerv2 can often be set with num_classes directly\n",
    "                model = timm.create_model(model_name, pretrained=True, num_classes=1)\n",
    "            else:\n",
    "                model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "            # Step 2: Custom Head Replacement Logic\n",
    "            # This block replaces the generic `if/elif hasattr(model, 'fc')` etc.\n",
    "            # to handle the specific models that were failing.\n",
    "\n",
    "            # Handled by num_classes=1 during creation for efficientformerv2_s0\n",
    "            if model_name == 'efficientformerv2_s0':\n",
    "                if model.head.out_features != 1: # Double check if it was correctly set\n",
    "                    # Fallback if num_classes=1 didn't work as expected\n",
    "                    print(f\"Warning: {model_name} num_classes=1 failed, attempting manual head adjustment.\")\n",
    "                    if hasattr(model, 'head') and isinstance(model.head, nn.Linear):\n",
    "                        model.head = nn.Linear(model.head.in_features, 1)\n",
    "                    else:\n",
    "                        raise NotImplementedError(f\"Manual head replacement for {model_name} needs review.\")\n",
    "            elif model_name == 'convnext_tiny' or model_name == 'convnext_nano':\n",
    "                # ConvNeXt models have a head.fc\n",
    "                model.head.fc = nn.Linear(model.head.fc.in_features, 1)\n",
    "            elif model_name == 'regnety_040':\n",
    "                # RegNet models typically have a 'head' that needs pooling and flattening\n",
    "                # Inspecting 'regnety_040' reveals model.head.fc, but it's part of a more complex structure\n",
    "                # A more robust approach for these is Sequential with pooling\n",
    "                # We need to get the feature size before the original head\n",
    "                # A common pattern for models with spatial output before head\n",
    "                num_features = model.head.in_features # This gets the input features for the original head\n",
    "                model.head = nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(num_features, 1)\n",
    "                )\n",
    "            elif model_name == 'coatnet_0_224':\n",
    "                # coatnet_0_224 needs manual replacement, often model.fc\n",
    "                if hasattr(model, 'fc'):\n",
    "                    model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"Head replacement for {model_name} needs specific inspection.\")\n",
    "            elif model_name.startswith('swin_') or model_name.startswith('hiera_'):\n",
    "                # Swin and Hiera are Vision Transformers, their head typically requires pooling before flattening\n",
    "                # model.num_features is usually reliable for ViT-like models\n",
    "                model.head = nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1), # Ensure spatial dimensions are reduced to 1x1\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(model.num_features, 1)\n",
    "                )\n",
    "            elif model_name == 'crossvit_tiny_240':\n",
    "                # CrossViT's head is a ModuleList containing several components.\n",
    "                # The final linear layer is often within a 'mlp' block or similar.\n",
    "                # Based on inspection, the final linear layer is usually `model.head.mlp.fc` or `model.head.layers[-1]`\n",
    "                if hasattr(model.head, 'mlp') and hasattr(model.head.mlp, 'fc'):\n",
    "                    model.head.mlp.fc = nn.Linear(model.head.mlp.fc.in_features, 1)\n",
    "                elif hasattr(model.head, 'proj'): # Some CrossViT variants use 'proj'\n",
    "                    model.head.proj = nn.Linear(model.head.proj.in_features, 1)\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"CrossViT head replacement for {model_name} needs specific inspection.\")\n",
    "            elif model_name == 'maxvit_tiny_rw_224':\n",
    "                # MaxViT has a `head` attribute which is a `ClassifierHead` object.\n",
    "                # Its final linear layer is usually accessible via an attribute within this head, e.g., `model.head.fc`\n",
    "                if hasattr(model.head, 'fc'):\n",
    "                    model.head.fc = nn.Linear(model.head.fc.in_features, 1)\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"MaxViT head replacement for {model_name} needs specific inspection.\")\n",
    "            elif model_name == 'mambaout_tiny':\n",
    "                # Mambaout has a custom head. The final linear layer is usually `model.head`\n",
    "                if hasattr(model, 'head') and isinstance(model.head, nn.Linear):\n",
    "                    model.head = nn.Linear(model.head.in_features, 1)\n",
    "                elif hasattr(model, 'norm_head') and hasattr(model.norm_head, 'head') and isinstance(model.norm_head.head, nn.Linear):\n",
    "                    model.norm_head.head = nn.Linear(model.norm_head.head.in_features, 1)\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"Mambaout head replacement for {model_name} needs specific inspection (complex).\")\n",
    "            elif model_name == 'mobileone_s1':\n",
    "                # MobileOne has a 'classifier' which is a sequential containing a linear layer\n",
    "                if hasattr(model, 'classifier') and isinstance(model.classifier, nn.Sequential):\n",
    "                    if hasattr(model.classifier[-1], 'in_features'):\n",
    "                        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 1)\n",
    "                    else:\n",
    "                        raise NotImplementedError(f\"MobileOne classifier last layer in_features not found.\")\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"MobileOne classifier replacement for {model_name} needs specific inspection.\")\n",
    "            elif hasattr(model, 'fc'):\n",
    "                model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "            elif hasattr(model, 'classifier'):\n",
    "                model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "            elif hasattr(model, 'head'):\n",
    "                # Generic head replacement for models where 'head' is directly a Linear layer\n",
    "                if isinstance(model.head, nn.Linear):\n",
    "                    model.head = nn.Linear(model.head.in_features, 1)\n",
    "                else:\n",
    "                    # Fallback for models where 'head' is a Sequential or other complex type\n",
    "                    # and requires more specific handling not caught above\n",
    "                    raise NotImplementedError(f\"Complex 'head' type for {model_name}, needs specific replacement.\")\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Head replacement not implemented for {model_name}\")\n",
    "\n",
    "            learn = Learner(chosen_dls, model, metrics=metrics, loss_func=loss_func) # Pass loss_func here\n",
    "\n",
    "            # Fine-tune with given epochs\n",
    "            learn.fine_tune(epochs) # Use the epochs parameter from the function\n",
    "\n",
    "            learners[model_name] = learn\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in training {model_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up and fine-tuning resnet50d...\n",
      "Datablock Variant: 2...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60.628994</td>\n",
       "      <td>20.774075</td>\n",
       "      <td>3.381304</td>\n",
       "      <td>4.449221</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/20 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='22' class='' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      28.21% [22/78 00:09&lt;00:24 16.1002]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming dls is your DataLoaders with regression targets\n",
    "learners = fine_tune_models(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving resnet50 learner to model/resnet50/model.pkl\n",
      "Saving efficientnet_b3 learner to model/efficientnet_b3/model.pkl\n",
      "Saving densenet121 learner to model/densenet121/model.pkl\n",
      "Saving resnet34 learner to model/resnet34/model.pkl\n",
      "Saving mobilenetv3_large_100 learner to model/mobilenetv3_large_100/model.pkl\n",
      "Saving efficientnet_b0 learner to model/efficientnet_b0/model.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# learners: dict of {model_name: Learner}\n",
    "for model_name, learn in learners.items():\n",
    "    folder_tag = \"\"\n",
    "    folder_path = f\"model/{model_name}{folder_tag}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    export_path = os.path.join(folder_path, \"model.pkl\")\n",
    "    print(f\"Saving {model_name} learner to {export_path}\")\n",
    "    learn.export(export_path)\n",
    "\n",
    "    # Get final metrics from recorder\n",
    "    # learn.recorder.values is a list of lists: one per epoch, each containing [train_loss, valid_loss, metric1, metric2, ...]\n",
    "    # learn.recorder.metric_names is the header for these values (first is 'train_loss', second 'valid_loss', etc.)\n",
    "    final_epoch_metrics = learn.recorder.values[-1]  # last epoch\n",
    "    metric_names = learn.recorder.metric_names[1:-1]  # skip 'epoch' at start and empty string at end\n",
    "\n",
    "    # Build metrics string\n",
    "    metrics_str = \"Final epoch metrics:\\n\"\n",
    "    for name, val in zip(metric_names, final_epoch_metrics[1:]):  # skip train_loss if you want\n",
    "        metrics_str += f\"{name}: {val:.6f}\\n\"\n",
    "\n",
    "    # Write to metrics.txt\n",
    "    metrics_path = os.path.join(folder_path, \"metrics.txt\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        f.write(metrics_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7594816,
     "sourceId": 12076934,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
