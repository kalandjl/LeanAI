{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c0b377-1fce-4b19-9e77-0cf81adaf0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('data/bodyfat_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4549e8-2b72-4df0-9ec5-5b0f668680bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>meanPrediction</th>\n",
       "      <th>medianPrediction</th>\n",
       "      <th>bfPredictions</th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>image_3</th>\n",
       "      <th>image_4</th>\n",
       "      <th>image_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leanest ive ever been. Never seen veins like t...</td>\n",
       "      <td>https://www.reddit.com/gallery/1b6k5jh</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let me know. 78kg :)</td>\n",
       "      <td>https://i.redd.it/4occeq9wdd2c1.jpg</td>\n",
       "      <td>9.80</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[9, 10, 10, 9, 11]</td>\n",
       "      <td>https://i.redd.it/4occeq9wdd2c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is my bf% I believe it’s around 13-14%</td>\n",
       "      <td>https://i.redd.it/lvfmowq0zhh91.jpg</td>\n",
       "      <td>14.33</td>\n",
       "      <td>13.5</td>\n",
       "      <td>[13, 19, 14, 14, 13, 13]</td>\n",
       "      <td>https://i.redd.it/lvfmowq0zhh91.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25F | 4'11\" | 107 lbs</td>\n",
       "      <td>https://www.reddit.com/gallery/1e30z2f</td>\n",
       "      <td>23.33</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[20, 26, 24]</td>\n",
       "      <td>https://preview.redd.it/25f-411-107-lbs-v0-4lm...</td>\n",
       "      <td>https://preview.redd.it/25f-411-107-lbs-v0-huc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bodyfat?</td>\n",
       "      <td>https://www.reddit.com/gallery/1ktwao9</td>\n",
       "      <td>17.80</td>\n",
       "      <td>18.0</td>\n",
       "      <td>[18, 16, 18, 15, 22]</td>\n",
       "      <td>https://preview.redd.it/8ekhv0d4xl2f1.jpg?widt...</td>\n",
       "      <td>https://preview.redd.it/rwkt50d4xl2f1.jpg?widt...</td>\n",
       "      <td>https://preview.redd.it/vau412d4xl2f1.jpg?widt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>[GMBF] 6'1 220LBS Any estimates appreciated!</td>\n",
       "      <td>https://i.redd.it/z543jfquva731.jpg</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[12]</td>\n",
       "      <td>https://i.redd.it/z543jfquva731.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>[GMBF] (M/22/6'2\"/195lbs)</td>\n",
       "      <td>https://i.imgur.com/PY44dK5.jpg</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.5</td>\n",
       "      <td>[11, 9, 10, 12]</td>\n",
       "      <td>https://i.imgur.com/PY44dK5.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>[GMBF] M/26/6'1/191lbs - down from 245lbs</td>\n",
       "      <td>https://i.imgur.com/pWGT7nV.jpg</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[15]</td>\n",
       "      <td>https://i.imgur.com/pWGT7nV.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>[GMBF] (M/26/5’10”/153lbs to 168lbs) What woul...</td>\n",
       "      <td>https://i.redd.it/lc2q2svumrt11.jpg</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[10, 14]</td>\n",
       "      <td>https://i.redd.it/lc2q2svumrt11.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Thoughts?</td>\n",
       "      <td>https://i.redd.it/3yube1tanu1f1.jpeg</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.5</td>\n",
       "      <td>[14, 13]</td>\n",
       "      <td>https://i.redd.it/3yube1tanu1f1.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Leanest ive ever been. Never seen veins like t...   \n",
       "1                                 Let me know. 78kg :)   \n",
       "2          What is my bf% I believe it’s around 13-14%   \n",
       "3                               25F | 4'11\" | 107 lbs    \n",
       "4                                             Bodyfat?   \n",
       "..                                                 ...   \n",
       "792       [GMBF] 6'1 220LBS Any estimates appreciated!   \n",
       "793                          [GMBF] (M/22/6'2\"/195lbs)   \n",
       "794          [GMBF] M/26/6'1/191lbs - down from 245lbs   \n",
       "795  [GMBF] (M/26/5’10”/153lbs to 168lbs) What woul...   \n",
       "796                                          Thoughts?   \n",
       "\n",
       "                                        url  meanPrediction  medianPrediction  \\\n",
       "0    https://www.reddit.com/gallery/1b6k5jh            8.00               8.0   \n",
       "1       https://i.redd.it/4occeq9wdd2c1.jpg            9.80              10.0   \n",
       "2       https://i.redd.it/lvfmowq0zhh91.jpg           14.33              13.5   \n",
       "3    https://www.reddit.com/gallery/1e30z2f           23.33              24.0   \n",
       "4    https://www.reddit.com/gallery/1ktwao9           17.80              18.0   \n",
       "..                                      ...             ...               ...   \n",
       "792     https://i.redd.it/z543jfquva731.jpg           12.00              12.0   \n",
       "793         https://i.imgur.com/PY44dK5.jpg           10.50              10.5   \n",
       "794         https://i.imgur.com/pWGT7nV.jpg           15.00              15.0   \n",
       "795     https://i.redd.it/lc2q2svumrt11.jpg           12.00              12.0   \n",
       "796    https://i.redd.it/3yube1tanu1f1.jpeg           13.50              13.5   \n",
       "\n",
       "                bfPredictions  \\\n",
       "0                         [8]   \n",
       "1          [9, 10, 10, 9, 11]   \n",
       "2    [13, 19, 14, 14, 13, 13]   \n",
       "3                [20, 26, 24]   \n",
       "4        [18, 16, 18, 15, 22]   \n",
       "..                        ...   \n",
       "792                      [12]   \n",
       "793           [11, 9, 10, 12]   \n",
       "794                      [15]   \n",
       "795                  [10, 14]   \n",
       "796                  [14, 13]   \n",
       "\n",
       "                                               image_1  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                  https://i.redd.it/4occeq9wdd2c1.jpg   \n",
       "2                  https://i.redd.it/lvfmowq0zhh91.jpg   \n",
       "3    https://preview.redd.it/25f-411-107-lbs-v0-4lm...   \n",
       "4    https://preview.redd.it/8ekhv0d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "792                https://i.redd.it/z543jfquva731.jpg   \n",
       "793                    https://i.imgur.com/PY44dK5.jpg   \n",
       "794                    https://i.imgur.com/pWGT7nV.jpg   \n",
       "795                https://i.redd.it/lc2q2svumrt11.jpg   \n",
       "796               https://i.redd.it/3yube1tanu1f1.jpeg   \n",
       "\n",
       "                                               image_2  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    https://preview.redd.it/25f-411-107-lbs-v0-huc...   \n",
       "4    https://preview.redd.it/rwkt50d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "792                                                NaN   \n",
       "793                                                NaN   \n",
       "794                                                NaN   \n",
       "795                                                NaN   \n",
       "796                                                NaN   \n",
       "\n",
       "                                               image_3  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    https://preview.redd.it/vau412d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "792                                                NaN   \n",
       "793                                                NaN   \n",
       "794                                                NaN   \n",
       "795                                                NaN   \n",
       "796                                                NaN   \n",
       "\n",
       "                                               image_4  image_5  \n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...      NaN  \n",
       "1                                                  NaN      NaN  \n",
       "2                                                  NaN      NaN  \n",
       "3                                                  NaN      NaN  \n",
       "4                                                  NaN      NaN  \n",
       "..                                                 ...      ...  \n",
       "792                                                NaN      NaN  \n",
       "793                                                NaN      NaN  \n",
       "794                                                NaN      NaN  \n",
       "795                                                NaN      NaN  \n",
       "796                                                NaN      NaN  \n",
       "\n",
       "[797 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865e79e0-2e1c-4672-8a10-969a55f38752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import requests\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "\n",
    "def download_and_crop_images(df, output_dir=\"images\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_cols = [f\"image_{i}\" for i in range(1, 6)]\n",
    "\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "    def crop_upper_body_cv2(img):\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(img_rgb)\n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            h, w, _ = img.shape\n",
    "\n",
    "            xs = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * w,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * w]\n",
    "\n",
    "            ys = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * h,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * h]\n",
    "\n",
    "            xmin, xmax = int(min(xs)), int(max(xs))\n",
    "            ymin, ymax = int(min(ys)), int(max(ys))\n",
    "\n",
    "            # Add padding\n",
    "            pad_x = 20\n",
    "            pad_y = 20\n",
    "            xmin = max(xmin - pad_x, 0)\n",
    "            xmax = min(xmax + pad_x, w)\n",
    "            ymin = max(ymin - pad_y, 0)\n",
    "            ymax = min(ymax + pad_y, h)\n",
    "\n",
    "            # Expand box\n",
    "            expand = int((xmax - xmin) * 0.3)\n",
    "            xmin = max(xmin - expand, 0)\n",
    "            xmax = min(xmax + expand, w)\n",
    "\n",
    "            cropped = img[ymin:ymax, xmin:xmax]\n",
    "            return cropped\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    seen_urls = set()\n",
    "    image_count = 0\n",
    "    failed = 0\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        for col in image_cols:\n",
    "            url = row.get(col)\n",
    "            if isinstance(url, str) and url.startswith(\"http\") and url not in seen_urls:\n",
    "                try:\n",
    "                    response = requests.get(url, timeout=10)\n",
    "                    if response.status_code == 200:\n",
    "                        img_arr = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "                        img = cv2.imdecode(img_arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "                        if img is None:\n",
    "                            raise ValueError(\"Downloaded image could not be decoded\")\n",
    "\n",
    "                        cropped = crop_upper_body_cv2(img)\n",
    "                        final_img = cropped if cropped is not None else img\n",
    "                        final_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)\n",
    "                        pil_img = Image.fromarray(final_img)\n",
    "\n",
    "                        file_ext = url.split('.')[-1].split('?')[0]\n",
    "                        file_name = f\"{idx}_{col}.{file_ext}\"\n",
    "                        file_path = os.path.join(output_dir, file_name)\n",
    "                        pil_img.save(file_path)\n",
    "\n",
    "                        seen_urls.add(url)\n",
    "                        image_count += 1\n",
    "                    else:\n",
    "                        failed += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading or processing {url}: {e}\")\n",
    "                    failed += 1\n",
    "\n",
    "    print(f\"\\n✔️ Downloaded and cropped {image_count} unique images to '{output_dir}/'\")\n",
    "    if failed:\n",
    "        print(f\"⚠️ {failed} images failed to download or process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9876b101-99d9-44d3-9edd-4db973cafa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_csv(df, output_csv=\"image_labels.csv\", label_col=\"meanPrediction\", image_prefix=\"image_\", output_dir=\"images\"):\n",
    "    # Ensure column names are stripped of whitespace\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    image_cols = [col for col in df.columns if col.startswith(image_prefix)]\n",
    "    records = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        label = row[label_col]\n",
    "        for col in image_cols:\n",
    "            url = row.get(col)\n",
    "            if isinstance(url, str) and url.startswith(\"http\"):\n",
    "                ext = url.split('.')[-1].split('?')[0].lower()\n",
    "                ext = ext if ext in ['jpg', 'jpeg', 'png', 'webp'] else 'jpg'\n",
    "                filename = f\"{idx}_{col}.{ext}\"\n",
    "                records.append({\"filename\": filename, \"target\": label})\n",
    "    \n",
    "    df_out = pd.DataFrame(records)\n",
    "    df_out.to_csv(output_csv, index=False)\n",
    "    print(f\"Created {output_csv} with {len(df_out)} labeled images\")\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "940a2b9a-56aa-4b9b-a965-c82eab37222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749719949.115947 4755906 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M4\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1749719949.200215 4756050 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749719949.216053 4756051 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749719949.275046 4756048 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      " 44%|██████████████████████████████████████████▎                                                      | 348/797 [01:53<02:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading or processing https://preview.redd.it/5jpfqogf6qke1.jpg?width=320&crop=smart&blur=36.4&format=pjpg&auto=webp&s=867bff674fe18a5152f94b3b96aa454a5734dee3: unknown file extension: .4&format=pjpg&auto=webp&s=867bff674fe18a5152f94b3b96aa454a5734dee3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████████████████▊                | 664/797 [03:48<01:29,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading or processing https://preview.redd.it/auo4rp9xb97c1.jpg?width=320&crop=smart&blur=34.6&format=pjpg&auto=webp&s=7eca5ed1bdd065632a6c7eee2b66605c9d993c45: unknown file extension: .6&format=pjpg&auto=webp&s=7eca5ed1bdd065632a6c7eee2b66605c9d993c45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 797/797 [04:47<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✔️ Downloaded and cropped 1563 unique images to 'images/'\n",
      "⚠️ 20 images failed to download or process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_and_crop_images(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8966a08-ea3d-4287-8194-cc288e8a09c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created image_labels.csv with 1583 labeled images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_image_1.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_image_2.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_image_3.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_image_4.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_image_1.jpg</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  target\n",
       "0  0_image_1.jpg     8.0\n",
       "1  0_image_2.jpg     8.0\n",
       "2  0_image_3.jpg     8.0\n",
       "3  0_image_4.jpg     8.0\n",
       "4  1_image_1.jpg     9.8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = create_regression_csv(df) \n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9f8e09-22b7-472a-bba3-0d7c297279d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "failed = verify_images(get_image_files(Path('images')))\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
