{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch, numpy as np, pandas as pd\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_image_1.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_image_2.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_image_3.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_image_4.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_image_1.jpg</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>791_image_1.jpg</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>792_image_1.jpg</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>793_image_1.jpg</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>794_image_1.jpg</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>795_image_1.jpeg</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1580 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  target\n",
       "0        0_image_1.jpg     8.0\n",
       "1        0_image_2.jpg     8.0\n",
       "2        0_image_3.jpg     8.0\n",
       "3        0_image_4.jpg     8.0\n",
       "4        1_image_1.jpg     9.8\n",
       "...                ...     ...\n",
       "1575   791_image_1.jpg    12.0\n",
       "1576   792_image_1.jpg    10.5\n",
       "1577   793_image_1.jpg    15.0\n",
       "1578   794_image_1.jpg    12.0\n",
       "1579  795_image_1.jpeg    13.5\n",
       "\n",
       "[1580 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(Path('data/image_labels.csv'))\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: No NaN values found in 'target' column (good).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "initial_nan_labels_count = df_labels['target'].isna().sum()\n",
    "if initial_nan_labels_count > 0:\n",
    "    print(f\"DEBUG: Found {initial_nan_labels_count} NaN values in 'target' column. Dropping rows with NaN targets.\")\n",
    "    df_labels.dropna(subset=['target'], inplace=True)\n",
    "else:\n",
    "    print(\"DEBUG: No NaN values found in 'target' column.\")\n",
    "\n",
    "train_df, valid_df = train_test_split(df_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_label_dict = dict(zip(train_df['filename'], train_df['target']))\n",
    "valid_label_dict = dict(zip(valid_df['filename'], valid_df['target']))\n",
    "all_label_dict = {**train_label_dict, **valid_label_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DEBUG: Train labels: {len(train_label_dict)} | Valid labels: {len(valid_label_dict)}\")\n",
    "\n",
    "# Get all image files\n",
    "path = Path('images')\n",
    "print(f\"DEBUG: Image path set to: {path}\")\n",
    "\n",
    "all_image_files = get_image_files(path)\n",
    "print(f\"DEBUG: Total image files found by get_image_files: {len(all_image_files)}\")\n",
    "\n",
    "# Filter image files to only those with matching labels\n",
    "processable_image_files = [f for f in all_image_files if f.name in all_label_dict]\n",
    "print(f\"DEBUG: Processable image files (with matching labels): {len(processable_image_files)}\")\n",
    "\n",
    "# Safety check\n",
    "if len(processable_image_files) == 0:\n",
    "    print(\"CERROR: No processable image files found (no images match labels or vice-versa).\")\n",
    "    if all_image_files and all_label_dict:\n",
    "        print(f\"  Sample image file: {all_image_files[0].name}\")\n",
    "        print(f\"  Sample label key: {next(iter(all_label_dict.keys()))}\")\n",
    "        if all_image_files[0].name not in all_label_dict and all_image_files[0].name.split('.')[0] in [k.split('.')[0] for k in all_label_dict.keys()]:\n",
    "            print(\" Filename extensions might differ between image files and label keys.\")\n",
    "    raise ValueError(\"Cannot create DataLoaders: No matching image files and labels.\")\n",
    "\n",
    "# Helper function to get label\n",
    "def get_y_func(fn):\n",
    "    key = fn.name\n",
    "    if key not in all_label_dict:\n",
    "        print(f\"DEBUG ERROR: Label not found for: {key} during get_y_func call. This should not happen if pre-filtered.\")\n",
    "        raise ValueError(f\"Label not found for: {key}\")\n",
    "    return all_label_dict[key]\n",
    "\n",
    "# Generate index lists for DataBlock IndexSplitter\n",
    "filename_to_index = {f.name: i for i, f in enumerate(processable_image_files)}\n",
    "valid_idxs = [filename_to_index[fname] for fname in valid_df['filename'] if fname in filename_to_index]\n",
    "splitter = IndexSplitter(valid_idxs)\n",
    "\n",
    "def convert_to_rgb(img):\n",
    "    return img.convert('RGB')\n",
    "\n",
    "# Use your existing setup for labels, image files, get_y_func, splitter, etc.\n",
    "\n",
    "def get_datablock_variant(variant:int):\n",
    "    \"\"\"\n",
    "    Returns a DataBlock with different augmentations depending on variant 1, 2, or 3.\n",
    "    \"\"\"\n",
    "    # Base parameters from your original\n",
    "    get_items_func = lambda _: processable_image_files\n",
    "    splitter_func = splitter\n",
    "    get_y_func_func = get_y_func\n",
    "    item_tfms_base = RandomResizedCrop(244, min_scale=0.75)\n",
    "\n",
    "    # Different batch transforms per variant\n",
    "    if variant == 1:\n",
    "        batch_tfms_variant = aug_transforms(\n",
    "            do_flip=False,\n",
    "            max_rotate=2,\n",
    "            max_zoom=1.05,\n",
    "            max_lighting=0.1,\n",
    "            max_warp=0.,\n",
    "            p_affine=0.3,\n",
    "            p_lighting=0.3\n",
    "        )\n",
    "    elif variant == 2:\n",
    "        batch_tfms_variant = aug_transforms(\n",
    "            do_flip=True,\n",
    "            max_rotate=10,\n",
    "            max_zoom=1.2,\n",
    "            max_lighting=0.2,\n",
    "            max_warp=0.2,\n",
    "            p_affine=0.5,\n",
    "            p_lighting=0.5\n",
    "        )\n",
    "    elif variant == 3:\n",
    "        batch_tfms_variant = aug_transforms(\n",
    "            do_flip=True,\n",
    "            max_rotate=20,\n",
    "            max_zoom=1.3,\n",
    "            max_lighting=0.3,\n",
    "            max_warp=0.3,\n",
    "            p_affine=0.7,\n",
    "            p_lighting=0.7\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"variant must be 1, 2, or 3\")\n",
    "\n",
    "    return DataBlock(\n",
    "        blocks=(ImageBlock, RegressionBlock),\n",
    "        get_items=get_items_func,\n",
    "        splitter=splitter_func,\n",
    "        get_y=get_y_func_func,\n",
    "        item_tfms=item_tfms_base,\n",
    "        batch_tfms=batch_tfms_variant,\n",
    "        n_inp=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls1 = get_datablock_variant(1).dataloaders(path, bs=16)\n",
    "dls2 = get_datablock_variant(2).dataloaders(path, bs=16)\n",
    "dls3 = get_datablock_variant(3).dataloaders(path, bs=16)\n",
    "\n",
    "dls_list = [dls1, dls2, dls3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        abs_error = torch.abs(input - target)\n",
    "        quadratic = torch.minimum(abs_error, torch.tensor(self.delta))\n",
    "        linear = abs_error - quadratic\n",
    "        loss = 0.5 * quadratic**2 + self.delta * linear\n",
    "        return loss.mean()\n",
    "\n",
    "def mae(preds, targs):\n",
    "    # Ensure target shape matches preds\n",
    "    if targs.ndim == 1:\n",
    "        targs = targs.unsqueeze(1)\n",
    "    return nn.L1Loss()(preds, targs)\n",
    "\n",
    "class RMCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        error_cubed = torch.abs(input - target) ** 3\n",
    "        mean_cubed_error = torch.mean(error_cubed)\n",
    "        loss = torch.pow(mean_cubed_error, 1/3)\n",
    "        return loss  # must be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from fastai.vision.all import *\n",
    "\n",
    "model_name='efficientnet_b3'\n",
    "\n",
    "# Create model with correct input size\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "# Replace the classification head with a regression head\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "\n",
    "# Create learner with the pre-configured model\n",
    "learn = Learner(dls, model, metrics=[rmse, mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.recorder.values[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have a working model! For example, it predicts this picture at 13% bodyfat (not so far off in my opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf,_,probs = learn.predict(PILImage.create('images/248_image_2.jpg'))\n",
    "print(f\"Bodyfat prediction: {probs[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_tag=\"\"\n",
    "path = f\"model/{model_name}{folder_tag}/model.pkl\"\n",
    "learn.export(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_models(dls, models=None, epochs=3, loss_func=None):\n",
    "\n",
    "    db_varient = random.randint(1, 3)\n",
    "    chosen_dls = random.choice(db_varient)\n",
    "    metrics=[rmse, mae]\n",
    "    \"\"\"\n",
    "    Creates, fine-tunes, and returns multiple timm learners for regression.\n",
    "\n",
    "    Args:\n",
    "        dls: fastai DataLoaders\n",
    "        models: list of timm model names (default below)\n",
    "        epochs: number of epochs to fine-tune each model\n",
    "        lr: learning rate for fine_tune\n",
    "        loss_func: loss function (default MSELossFlat)\n",
    "        metrics: list of metrics (default mae)\n",
    "\n",
    "    Returns:\n",
    "        dict of {model_name: learner}\n",
    "    \"\"\"\n",
    "    if models is None:\n",
    "        models = [\n",
    "            'resnet50',\n",
    "            'efficientnet_b3',\n",
    "            'densenet121',\n",
    "            'convnext_base',\n",
    "            'vit_base_patch16_224',\n",
    "            'resnet34',\n",
    "            'mobilenetv3_large_100',\n",
    "            'efficientnet_b0',\n",
    "            'regnety_400mf',\n",
    "            'beit_base_patch16_224'\n",
    "        ]\n",
    "    if loss_func is None:\n",
    "        loss_func = MSELossFlat()\n",
    "    if metrics is None:\n",
    "        metrics = [mae]\n",
    "\n",
    "    learners = {}\n",
    "\n",
    "    for model_name in models:\n",
    "        print(f\"Setting up and fine-tuning {model_name}...\")\n",
    "        print(f\"Datablock Varient: {db_varient}...\")\n",
    "\n",
    "        model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "        if hasattr(model, 'fc'):\n",
    "            model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "        elif hasattr(model, 'head'):\n",
    "            model.head = nn.Linear(model.head.in_features, 1)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Head replacement not implemented for {model_name}\")\n",
    "\n",
    "        learn = Learner(dls, model, metrics=metrics)\n",
    "\n",
    "        # fine_tune with given epochs and lr\n",
    "        try:\n",
    "\n",
    "            learn.fine_tune(epochs)\n",
    "        except:\n",
    "            print (f\"error in trained: model {model_name}\")\n",
    "            continue\n",
    "\n",
    "        learners[model_name] = learn\n",
    "\n",
    "    return learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming dls is your DataLoaders with regression targets\n",
    "learners = fine_tune_models(dls, epochs=12)\n",
    "\n",
    "# Access any learner after training:\n",
    "learners['resnet50'].show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learners' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# learners: dict of {model_name: Learner}\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, learn \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlearners\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m     folder_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfolder_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learners' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# learners: dict of {model_name: Learner}\n",
    "for model_name, learn in learners.items():\n",
    "    folder_tag = \"\"\n",
    "    folder_path = f\"model/{model_name}{folder_tag}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    export_path = os.path.join(folder_path, \"model.pkl\")\n",
    "    print(f\"Saving {model_name} learner to {export_path}\")\n",
    "    learn.export(export_path)\n",
    "\n",
    "    # Get final metrics from recorder\n",
    "    # learn.recorder.values is a list of lists: one per epoch, each containing [train_loss, valid_loss, metric1, metric2, ...]\n",
    "    # learn.recorder.metric_names is the header for these values (first is 'train_loss', second 'valid_loss', etc.)\n",
    "    final_epoch_metrics = learn.recorder.values[-1]  # last epoch\n",
    "    metric_names = learn.recorder.metric_names[1:-1]  # skip 'epoch' at start and empty string at end\n",
    "\n",
    "    # Build metrics string\n",
    "    metrics_str = \"Final epoch metrics:\\n\"\n",
    "    for name, val in zip(metric_names, final_epoch_metrics[1:]):  # skip train_loss if you want\n",
    "        metrics_str += f\"{name}: {val:.6f}\\n\"\n",
    "\n",
    "    # Write to metrics.txt\n",
    "    metrics_path = os.path.join(folder_path, \"metrics.txt\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        f.write(metrics_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7594816,
     "sourceId": 12076934,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
