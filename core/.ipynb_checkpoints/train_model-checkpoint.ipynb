{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch, numpy as np, pandas as pd\n",
    "from fastai.vision.all import *\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(Path('data/image_labels.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop NaNs and build the initial label dictionary\n",
    "initial_nan_labels_count = df_labels['target'].isna().sum()\n",
    "if initial_nan_labels_count > 0:\n",
    "    print(f\"DEBUG: Found {initial_nan_labels_count} NaN values in 'target' column. Dropping rows with NaN targets.\")\n",
    "    df_labels.dropna(subset=['target'], inplace=True)\n",
    "else:\n",
    "    print(\"DEBUG: No NaN values found in 'target' column (good).\")\n",
    "\n",
    "# Split into train and validation\n",
    "train_df, valid_df = train_test_split(df_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_label_dict = dict(zip(train_df['filename'], train_df['target']))\n",
    "valid_label_dict = dict(zip(valid_df['filename'], valid_df['target']))\n",
    "all_label_dict = {**train_label_dict, **valid_label_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make the datablock. For augmentations, we'll do all except warp (that might make the phyisquese look too different). We can see some of our datablock's examples with show_batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DEBUG: Train labels: {len(train_label_dict)} | Valid labels: {len(valid_label_dict)}\")\n",
    "\n",
    "# Get all image files\n",
    "path = Path('images')\n",
    "print(f\"DEBUG: Image path set to: {path}\")\n",
    "\n",
    "all_image_files = get_image_files(path)\n",
    "print(f\"DEBUG: Total image files found by get_image_files: {len(all_image_files)}\")\n",
    "\n",
    "# Filter image files to only those with matching labels\n",
    "processable_image_files = [f for f in all_image_files if f.name in all_label_dict]\n",
    "print(f\"DEBUG: Processable image files (with matching labels): {len(processable_image_files)}\")\n",
    "\n",
    "# Safety check\n",
    "if len(processable_image_files) == 0:\n",
    "    print(\"CERROR: No processable image files found (no images match labels or vice-versa).\")\n",
    "    if all_image_files and all_label_dict:\n",
    "        print(f\"  Sample image file: {all_image_files[0].name}\")\n",
    "        print(f\"  Sample label key: {next(iter(all_label_dict.keys()))}\")\n",
    "        if all_image_files[0].name not in all_label_dict and all_image_files[0].name.split('.')[0] in [k.split('.')[0] for k in all_label_dict.keys()]:\n",
    "            print(\" Filename extensions might differ between image files and label keys.\")\n",
    "    raise ValueError(\"Cannot create DataLoaders: No matching image files and labels.\")\n",
    "\n",
    "# Helper function to get label\n",
    "def get_y_func(fn):\n",
    "    key = fn.name\n",
    "    if key not in all_label_dict:\n",
    "        print(f\"DEBUG ERROR: Label not found for: {key} during get_y_func call. This should not happen if pre-filtered.\")\n",
    "        raise ValueError(f\"Label not found for: {key}\")\n",
    "    return all_label_dict[key]\n",
    "\n",
    "# Generate index lists for DataBlock IndexSplitter\n",
    "filename_to_index = {f.name: i for i, f in enumerate(processable_image_files)}\n",
    "valid_idxs = [filename_to_index[fname] for fname in valid_df['filename'] if fname in filename_to_index]\n",
    "splitter = IndexSplitter(valid_idxs)\n",
    "\n",
    "def convert_to_rgb(img):\n",
    "    return img.convert('RGB')\n",
    "\n",
    "# Transformations\n",
    "item_tfms = RandomResizedCrop(244, min_scale=0.75)\n",
    "\n",
    "batch_tfms = aug_transforms(\n",
    "    do_flip=False,\n",
    "    max_rotate=2,     \n",
    "    max_zoom=1.05,    \n",
    "    max_lighting=0.1, \n",
    "    max_warp=0.,\n",
    "    p_affine=0.3,     \n",
    "    p_lighting=0.3   \n",
    ")\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, RegressionBlock),\n",
    "    get_items=lambda _: processable_image_files,\n",
    "    splitter=splitter,\n",
    "    get_y=get_y_func,\n",
    "    item_tfms=item_tfms,\n",
    "    batch_tfms=batch_tfms,\n",
    "    n_inp=1\n",
    ")\n",
    "\n",
    "print(\"DEBUG: Attempting to create DataLoaders...\")\n",
    "try:\n",
    "    dls = dblock.dataloaders(path, bs=16)\n",
    "    print(\"DEBUG: DataLoaders created successfully.\")\n",
    "    print(f\"DEBUG: Number of training batches: {len(dls.train)}\")\n",
    "    print(f\"DEBUG: Number of validation batches: {len(dls.valid)}\")\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: Failed to create DataLoaders: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        abs_error = torch.abs(input - target)\n",
    "        quadratic = torch.minimum(abs_error, torch.tensor(self.delta))\n",
    "        linear = abs_error - quadratic\n",
    "        loss = 0.5 * quadratic**2 + self.delta * linear\n",
    "        return loss.mean()\n",
    "\n",
    "def mae(preds, targs):\n",
    "    # Ensure target shape matches preds\n",
    "    if targs.ndim == 1:\n",
    "        targs = targs.unsqueeze(1)\n",
    "    return nn.L1Loss()(preds, targs)\n",
    "\n",
    "class RMCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        error_cubed = torch.abs(input - target) ** 3\n",
    "        mean_cubed_error = torch.mean(error_cubed)\n",
    "        loss = torch.pow(mean_cubed_error, 1/3)\n",
    "        return loss  # must be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from fastai.vision.all import *\n",
    "\n",
    "model_name='efficientnet_b3'\n",
    "\n",
    "# Create model with correct input size\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=1)\n",
    "\n",
    "# Create learner with the pre-configured model\n",
    "learn = Learner(dls, model, metrics=[rsme, mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have a working model! For example, it predicts this picture at 13% bodyfat (not so far off in my opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf,_,probs = learn.predict(PILImage.create('images/248_image_2.jpg'))\n",
    "print(f\"Bodyfat prediction: {probs[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_tag=\"\"\n",
    "path = f\"model/{model_name}{folder_tag}/model.pkl\"\n",
    "learn.export(path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7594816,
     "sourceId": 12076934,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
