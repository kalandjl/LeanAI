{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c0b377-1fce-4b19-9e77-0cf81adaf0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('data/bodyfat_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4549e8-2b72-4df0-9ec5-5b0f668680bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>meanPrediction</th>\n",
       "      <th>medianPrediction</th>\n",
       "      <th>bfPredictions</th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>image_3</th>\n",
       "      <th>image_4</th>\n",
       "      <th>image_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leanest ive ever been. Never seen veins like t...</td>\n",
       "      <td>https://www.reddit.com/gallery/1b6k5jh</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let me know. 78kg :)</td>\n",
       "      <td>https://i.redd.it/4occeq9wdd2c1.jpg</td>\n",
       "      <td>9.80</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[9, 10, 10, 9, 11]</td>\n",
       "      <td>https://i.redd.it/4occeq9wdd2c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is my bf% I believe it’s around 13-14%</td>\n",
       "      <td>https://i.redd.it/lvfmowq0zhh91.jpg</td>\n",
       "      <td>14.33</td>\n",
       "      <td>13.5</td>\n",
       "      <td>[13, 19, 14, 14, 13, 13]</td>\n",
       "      <td>https://i.redd.it/lvfmowq0zhh91.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25F | 4'11\" | 107 lbs</td>\n",
       "      <td>https://www.reddit.com/gallery/1e30z2f</td>\n",
       "      <td>23.33</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[20, 26, 24]</td>\n",
       "      <td>https://preview.redd.it/25f-411-107-lbs-v0-4lm...</td>\n",
       "      <td>https://preview.redd.it/25f-411-107-lbs-v0-huc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bodyfat?</td>\n",
       "      <td>https://www.reddit.com/gallery/1ktwao9</td>\n",
       "      <td>17.80</td>\n",
       "      <td>18.0</td>\n",
       "      <td>[18, 16, 18, 15, 22]</td>\n",
       "      <td>https://preview.redd.it/8ekhv0d4xl2f1.jpg?widt...</td>\n",
       "      <td>https://preview.redd.it/rwkt50d4xl2f1.jpg?widt...</td>\n",
       "      <td>https://preview.redd.it/vau412d4xl2f1.jpg?widt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>[GMBF] 6'1 220LBS Any estimates appreciated!</td>\n",
       "      <td>https://i.redd.it/z543jfquva731.jpg</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[12]</td>\n",
       "      <td>https://i.redd.it/z543jfquva731.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>[GMBF] (M/22/6'2\"/195lbs)</td>\n",
       "      <td>https://i.imgur.com/PY44dK5.jpg</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.5</td>\n",
       "      <td>[11, 9, 10, 12]</td>\n",
       "      <td>https://i.imgur.com/PY44dK5.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>[GMBF] M/26/6'1/191lbs - down from 245lbs</td>\n",
       "      <td>https://i.imgur.com/pWGT7nV.jpg</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[15]</td>\n",
       "      <td>https://i.imgur.com/pWGT7nV.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>[GMBF] (M/26/5’10”/153lbs to 168lbs) What woul...</td>\n",
       "      <td>https://i.redd.it/lc2q2svumrt11.jpg</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[10, 14]</td>\n",
       "      <td>https://i.redd.it/lc2q2svumrt11.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>Thoughts?</td>\n",
       "      <td>https://i.redd.it/3yube1tanu1f1.jpeg</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.5</td>\n",
       "      <td>[14, 13]</td>\n",
       "      <td>https://i.redd.it/3yube1tanu1f1.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Leanest ive ever been. Never seen veins like t...   \n",
       "1                                 Let me know. 78kg :)   \n",
       "2          What is my bf% I believe it’s around 13-14%   \n",
       "3                               25F | 4'11\" | 107 lbs    \n",
       "4                                             Bodyfat?   \n",
       "..                                                 ...   \n",
       "801       [GMBF] 6'1 220LBS Any estimates appreciated!   \n",
       "802                          [GMBF] (M/22/6'2\"/195lbs)   \n",
       "803          [GMBF] M/26/6'1/191lbs - down from 245lbs   \n",
       "804  [GMBF] (M/26/5’10”/153lbs to 168lbs) What woul...   \n",
       "805                                          Thoughts?   \n",
       "\n",
       "                                        url  meanPrediction  medianPrediction  \\\n",
       "0    https://www.reddit.com/gallery/1b6k5jh            8.00               8.0   \n",
       "1       https://i.redd.it/4occeq9wdd2c1.jpg            9.80              10.0   \n",
       "2       https://i.redd.it/lvfmowq0zhh91.jpg           14.33              13.5   \n",
       "3    https://www.reddit.com/gallery/1e30z2f           23.33              24.0   \n",
       "4    https://www.reddit.com/gallery/1ktwao9           17.80              18.0   \n",
       "..                                      ...             ...               ...   \n",
       "801     https://i.redd.it/z543jfquva731.jpg           12.00              12.0   \n",
       "802         https://i.imgur.com/PY44dK5.jpg           10.50              10.5   \n",
       "803         https://i.imgur.com/pWGT7nV.jpg           15.00              15.0   \n",
       "804     https://i.redd.it/lc2q2svumrt11.jpg           12.00              12.0   \n",
       "805    https://i.redd.it/3yube1tanu1f1.jpeg           13.50              13.5   \n",
       "\n",
       "                bfPredictions  \\\n",
       "0                         [8]   \n",
       "1          [9, 10, 10, 9, 11]   \n",
       "2    [13, 19, 14, 14, 13, 13]   \n",
       "3                [20, 26, 24]   \n",
       "4        [18, 16, 18, 15, 22]   \n",
       "..                        ...   \n",
       "801                      [12]   \n",
       "802           [11, 9, 10, 12]   \n",
       "803                      [15]   \n",
       "804                  [10, 14]   \n",
       "805                  [14, 13]   \n",
       "\n",
       "                                               image_1  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                  https://i.redd.it/4occeq9wdd2c1.jpg   \n",
       "2                  https://i.redd.it/lvfmowq0zhh91.jpg   \n",
       "3    https://preview.redd.it/25f-411-107-lbs-v0-4lm...   \n",
       "4    https://preview.redd.it/8ekhv0d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "801                https://i.redd.it/z543jfquva731.jpg   \n",
       "802                    https://i.imgur.com/PY44dK5.jpg   \n",
       "803                    https://i.imgur.com/pWGT7nV.jpg   \n",
       "804                https://i.redd.it/lc2q2svumrt11.jpg   \n",
       "805               https://i.redd.it/3yube1tanu1f1.jpeg   \n",
       "\n",
       "                                               image_2  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    https://preview.redd.it/25f-411-107-lbs-v0-huc...   \n",
       "4    https://preview.redd.it/rwkt50d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "801                                                NaN   \n",
       "802                                                NaN   \n",
       "803                                                NaN   \n",
       "804                                                NaN   \n",
       "805                                                NaN   \n",
       "\n",
       "                                               image_3  \\\n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    https://preview.redd.it/vau412d4xl2f1.jpg?widt...   \n",
       "..                                                 ...   \n",
       "801                                                NaN   \n",
       "802                                                NaN   \n",
       "803                                                NaN   \n",
       "804                                                NaN   \n",
       "805                                                NaN   \n",
       "\n",
       "                                               image_4  image_5  \n",
       "0    https://preview.redd.it/leanest-ive-ever-been-...      NaN  \n",
       "1                                                  NaN      NaN  \n",
       "2                                                  NaN      NaN  \n",
       "3                                                  NaN      NaN  \n",
       "4                                                  NaN      NaN  \n",
       "..                                                 ...      ...  \n",
       "801                                                NaN      NaN  \n",
       "802                                                NaN      NaN  \n",
       "803                                                NaN      NaN  \n",
       "804                                                NaN      NaN  \n",
       "805                                                NaN      NaN  \n",
       "\n",
       "[806 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865e79e0-2e1c-4672-8a10-969a55f38752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_all_images(df, output_dir=\"raw_images\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_cols = [f\"image_{i}\" for i in range(1, 6)]\n",
    "    \n",
    "    seen_urls = set()\n",
    "    image_count = 0\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        for col in image_cols:\n",
    "            url = row.get(col)\n",
    "            if isinstance(url, str) and url.startswith(\"http\") and url not in seen_urls:\n",
    "                try:\n",
    "                    response = requests.get(url, timeout=10)\n",
    "                    if response.status_code == 200:\n",
    "                        file_ext = url.split('.')[-1].split('?')[0]\n",
    "                        file_name = f\"{idx}_{col}.{file_ext}\"\n",
    "                        file_path = os.path.join(output_dir, file_name)\n",
    "                        with open(file_path, \"wb\") as f:\n",
    "                            f.write(response.content)\n",
    "                        seen_urls.add(url)\n",
    "                        image_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "    print(f\"\\nDownloaded {image_count} unique images to '{output_dir}/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9876b101-99d9-44d3-9edd-4db973cafa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_csv(df, output_csv=\"image_labels.csv\", label_col=\"meanPrediction\", image_prefix=\"image_\", output_dir=\"images\"):\n",
    "    # Ensure column names are stripped of whitespace\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    image_cols = [col for col in df.columns if col.startswith(image_prefix)]\n",
    "    records = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        label = row[label_col]\n",
    "        for col in image_cols:\n",
    "            url = row.get(col)\n",
    "            if isinstance(url, str) and url.startswith(\"http\"):\n",
    "                ext = url.split('.')[-1].split('?')[0].lower()\n",
    "                ext = ext if ext in ['jpg', 'jpeg', 'png', 'webp'] else 'jpg'\n",
    "                filename = f\"{idx}_{col}.{ext}\"\n",
    "                records.append({\"filename\": filename, \"target\": label})\n",
    "    \n",
    "    df_out = pd.DataFrame(records)\n",
    "    df_out.to_csv(output_csv, index=False)\n",
    "    print(f\"Created {output_csv} with {len(df_out)} labeled images\")\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940a2b9a-56aa-4b9b-a965-c82eab37222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 806/806 [03:29<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloaded 1579 unique images to 'raw_images/'\n",
      "Created image_labels.csv with 1597 labeled images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_image_1.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_image_2.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_image_3.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_image_4.jpg</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_image_1.jpg</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  target\n",
       "0  0_image_1.jpg     8.0\n",
       "1  0_image_2.jpg     8.0\n",
       "2  0_image_3.jpg     8.0\n",
       "3  0_image_4.jpg     8.0\n",
       "4  1_image_1.jpg     9.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_all_images(df)  \n",
    "\n",
    "df_labels = create_regression_csv(df) \n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9f8e09-22b7-472a-bba3-0d7c297279d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "failed = verify_images(get_image_files(Path('raw_images')))\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f7875d-2c2d-4321-885e-56d986b4f0ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "def crop_upper_body(image_path):\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        print(f\"Failed to read image {image_path}\")\n",
    "        return None\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(img_rgb)\n",
    "\n",
    "    if not results.pose_landmarks:\n",
    "        print(f\"No pose detected in {image_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "        right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "        left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]\n",
    "        right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "        xs = [left_shoulder.x * w, right_shoulder.x * w, left_hip.x * w, right_hip.x * w]\n",
    "        ys = [left_shoulder.y * h, right_shoulder.y * h, left_hip.y * h, right_hip.y * h]\n",
    "\n",
    "        xmin, xmax = int(min(xs)), int(max(xs))\n",
    "        ymin, ymax = int(min(ys)), int(max(ys))\n",
    "\n",
    "        # Add padding around landmarks\n",
    "        pad_x = 20\n",
    "        pad_y = 20\n",
    "        xmin = max(xmin - pad_x, 0)\n",
    "        xmax = min(xmax + pad_x, w)\n",
    "        ymin = max(ymin - pad_y, 0)\n",
    "        ymax = min(ymax + pad_y, h)\n",
    "\n",
    "        # Final adjustment: widen the crop a little more (e.g., 10% of width)\n",
    "        box_width = xmax - xmin\n",
    "        expand = int(box_width * 0.1)  # Expand 10% on each side\n",
    "        xmin = max(xmin - expand, 0)\n",
    "        xmax = min(xmax + expand, w)\n",
    "\n",
    "        cropped = img[ymin:ymax, xmin:xmax]\n",
    "        cropped_rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "        return Image.fromarray(cropped_rgb)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error cropping {image_path}: {e}\")\n",
    "        return None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython",
   "language": "python",
   "name": "ipython_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
