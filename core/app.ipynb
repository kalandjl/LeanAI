{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37232027-ec6d-42b4-9527-9cdc35d80d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('model.pkl')\n",
    "\n",
    "!pip install -Uqq fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27959308-0205-47f7-b0f3-d9efef7ea418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n",
      "File size: 94592082 bytes\n",
      "Full path: /Users/kalanjarvis-loewen/Desktop/Coding/learning/ml/LeanAI/core/model.pkl\n",
      "File is a valid ZIP archive\n"
     ]
    }
   ],
   "source": [
    "print(f\"File exists: {path.exists()}\")\n",
    "print(f\"File size: {path.stat().st_size if path.exists() else 'N/A'} bytes\")\n",
    "print(f\"Full path: {path.absolute()}\")\n",
    "import zipfile\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(path, 'r') as zip_file:\n",
    "        print(\"File is a valid ZIP archive\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"File is corrupted or not a valid ZIP archive\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538cf9a8-f75a-43cc-9eb1-41641a2cdefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "model = load_learner(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0418039-8c31-4e06-a530-d97cea014351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(pre_img):\n",
    "    img = Image.open('images/0_image_1.jpg').convert('RGB')\n",
    "    return transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85c54614-0c29-43ed-b871-d27ccc49a649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input type: <class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.862442493438721\n"
     ]
    }
   ],
   "source": [
    "def predict_image(img):\n",
    "\n",
    "    if img is None:\n",
    "        return \"Please upload an image first\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Input type: {type(img)}\")\n",
    "\n",
    "        pil_img = PILImage.create(img)\n",
    "\n",
    "        \n",
    "        bf, _, preds = model.predict(pil_img)\n",
    "        \n",
    "        return float(preds[0])\n",
    "        \n",
    "    except Exception as e:\n",
    "        return print(f\"error: {e}\")\n",
    "\n",
    "pred = predict_image('images/0_image_1.jpg')               \n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "205660ab-df47-450f-b64b-1b051b86796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Body Fat Prediction\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        image_input = gr.Image(label=\"Upload Image\")\n",
    "        output = gr.Number(label=\"Predicted Value\")\n",
    "    \n",
    "    predict_btn = gr.Button(\"Predict\")\n",
    "    predict_btn.click(predict_image, inputs=image_input, outputs=output)\n",
    "\n",
    "#demo.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91085d66-78fe-442d-8ef5-0c2149933528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [95460]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:7866 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import threading\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/model/predict\")\n",
    "async def predict(request: Request):\n",
    "    data = await request.json()\n",
    "    # Do your model stuff here\n",
    "    return {\"received\": data}\n",
    "\n",
    "# Patch event loop so uvicorn can run inside Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run uvicorn in a background thread\n",
    "def run():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=7866)\n",
    "\n",
    "threading.Thread(target=run).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422188df-4ba2-4fd7-9d78-0cc721f7db99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython",
   "language": "python",
   "name": "ipython_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
