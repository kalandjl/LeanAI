{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12076934,"sourceType":"datasetVersion","datasetId":7594816}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif iskaggle: path = Path('../input/bodyfat-dataset')\nif iskaggle:\n    !pip install -Uqq fastai\nelse:\n    path = Path('bodyfat-dataset')\n    if not path.exists():\n        import zipfile,kaggle\n        kaggle.api.competition_download_cli(str(path))\n        zipfile.ZipFile(f'{path}.zip').extractall(path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:17:18.240980Z","iopub.execute_input":"2025-06-09T20:17:18.241258Z","iopub.status.idle":"2025-06-09T20:18:50.328192Z","shell.execute_reply.started":"2025-06-09T20:17:18.241229Z","shell.execute_reply":"2025-06-09T20:18:50.327435Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch, numpy as np, pandas as pd\n\ndf = pd.read_csv(path/'guessmybf_dataset.csv')\n\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:18:50.329861Z","iopub.execute_input":"2025-06-09T20:18:50.330216Z","iopub.status.idle":"2025-06-09T20:18:56.094891Z","shell.execute_reply.started":"2025-06-09T20:18:50.330173Z","shell.execute_reply":"2025-06-09T20:18:56.094032Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                 title  \\\n0    Leanest ive ever been. Never seen veins like t...   \n1                                 Let me know. 78kg :)   \n2          What is my bf% I believe it’s around 13-14%   \n3                               25F | 4'11\" | 107 lbs    \n4                                             Bodyfat?   \n..                                                 ...   \n969                                        Body Fat %?   \n970                       5’7, 20, 143, 13% body fat.    \n971           5’5 165lbs/74kg what body fat % am i at?   \n972  M19 169.8lbs 6’0 what’s my body fat and do I b...   \n973  What’s my body type or percentage ? I don’t lo...   \n\n                                        url  meanPrediction  medianPrediction  \\\n0    https://www.reddit.com/gallery/1b6k5jh            8.00               8.0   \n1       https://i.redd.it/4occeq9wdd2c1.jpg            9.80              10.0   \n2       https://i.redd.it/lvfmowq0zhh91.jpg           14.33              13.5   \n3    https://www.reddit.com/gallery/1e30z2f           23.33              24.0   \n4    https://www.reddit.com/gallery/1ktwao9           17.80              18.0   \n..                                      ...             ...               ...   \n969  https://www.reddit.com/gallery/142j5a1           12.00              12.0   \n970  https://www.reddit.com/gallery/1fdkwl1           20.00              20.0   \n971  https://www.reddit.com/gallery/13rnk8s            7.00               7.0   \n972    https://i.redd.it/hcbojzwjlmod1.jpeg           15.00              15.0   \n973   https://www.reddit.com/gallery/zsn760           29.67              29.0   \n\n                bfPredictions  \\\n0                         [8]   \n1          [9, 10, 10, 9, 11]   \n2    [13, 19, 14, 14, 13, 13]   \n3                [20, 26, 24]   \n4        [18, 16, 18, 15, 22]   \n..                        ...   \n969                      [12]   \n970                      [20]   \n971                    [6, 8]   \n972                      [15]   \n973  [33, 30, 25, 28, 35, 27]   \n\n                                               image_1  \\\n0    https://preview.redd.it/leanest-ive-ever-been-...   \n1                  https://i.redd.it/4occeq9wdd2c1.jpg   \n2                  https://i.redd.it/lvfmowq0zhh91.jpg   \n3    https://preview.redd.it/25f-411-107-lbs-v0-4lm...   \n4    https://preview.redd.it/8ekhv0d4xl2f1.jpg?widt...   \n..                                                 ...   \n969  https://preview.redd.it/body-fat-v0-gbp2nkr0ze...   \n970  https://preview.redd.it/57-20-143-13-body-fat-...   \n971  https://preview.redd.it/55-165lbs-74kg-what-bo...   \n972               https://i.redd.it/hcbojzwjlmod1.jpeg   \n973  https://preview.redd.it/whats-my-body-type-or-...   \n\n                                               image_2  \\\n0    https://preview.redd.it/leanest-ive-ever-been-...   \n1                                                  NaN   \n2                                                  NaN   \n3    https://preview.redd.it/25f-411-107-lbs-v0-huc...   \n4    https://preview.redd.it/rwkt50d4xl2f1.jpg?widt...   \n..                                                 ...   \n969  https://preview.redd.it/body-fat-v0-k42s9or0ze...   \n970  https://preview.redd.it/57-20-143-13-body-fat-...   \n971  https://preview.redd.it/55-165lbs-74kg-what-bo...   \n972                                                NaN   \n973  https://preview.redd.it/whats-my-body-type-or-...   \n\n                                               image_3  \\\n0    https://preview.redd.it/leanest-ive-ever-been-...   \n1                                                  NaN   \n2                                                  NaN   \n3                                                  NaN   \n4    https://preview.redd.it/vau412d4xl2f1.jpg?widt...   \n..                                                 ...   \n969  https://preview.redd.it/body-fat-v0-bxe5onr0ze...   \n970  https://preview.redd.it/57-20-143-13-body-fat-...   \n971  https://preview.redd.it/55-165lbs-74kg-what-bo...   \n972                                                NaN   \n973                                                NaN   \n\n                                               image_4  image_5  \n0    https://preview.redd.it/leanest-ive-ever-been-...      NaN  \n1                                                  NaN      NaN  \n2                                                  NaN      NaN  \n3                                                  NaN      NaN  \n4                                                  NaN      NaN  \n..                                                 ...      ...  \n969                                                NaN      NaN  \n970  https://preview.redd.it/57-20-143-13-body-fat-...      NaN  \n971                                                NaN      NaN  \n972                                                NaN      NaN  \n973                                                NaN      NaN  \n\n[974 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>url</th>\n      <th>meanPrediction</th>\n      <th>medianPrediction</th>\n      <th>bfPredictions</th>\n      <th>image_1</th>\n      <th>image_2</th>\n      <th>image_3</th>\n      <th>image_4</th>\n      <th>image_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Leanest ive ever been. Never seen veins like t...</td>\n      <td>https://www.reddit.com/gallery/1b6k5jh</td>\n      <td>8.00</td>\n      <td>8.0</td>\n      <td>[8]</td>\n      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n      <td>https://preview.redd.it/leanest-ive-ever-been-...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Let me know. 78kg :)</td>\n      <td>https://i.redd.it/4occeq9wdd2c1.jpg</td>\n      <td>9.80</td>\n      <td>10.0</td>\n      <td>[9, 10, 10, 9, 11]</td>\n      <td>https://i.redd.it/4occeq9wdd2c1.jpg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is my bf% I believe it’s around 13-14%</td>\n      <td>https://i.redd.it/lvfmowq0zhh91.jpg</td>\n      <td>14.33</td>\n      <td>13.5</td>\n      <td>[13, 19, 14, 14, 13, 13]</td>\n      <td>https://i.redd.it/lvfmowq0zhh91.jpg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25F | 4'11\" | 107 lbs</td>\n      <td>https://www.reddit.com/gallery/1e30z2f</td>\n      <td>23.33</td>\n      <td>24.0</td>\n      <td>[20, 26, 24]</td>\n      <td>https://preview.redd.it/25f-411-107-lbs-v0-4lm...</td>\n      <td>https://preview.redd.it/25f-411-107-lbs-v0-huc...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bodyfat?</td>\n      <td>https://www.reddit.com/gallery/1ktwao9</td>\n      <td>17.80</td>\n      <td>18.0</td>\n      <td>[18, 16, 18, 15, 22]</td>\n      <td>https://preview.redd.it/8ekhv0d4xl2f1.jpg?widt...</td>\n      <td>https://preview.redd.it/rwkt50d4xl2f1.jpg?widt...</td>\n      <td>https://preview.redd.it/vau412d4xl2f1.jpg?widt...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>969</th>\n      <td>Body Fat %?</td>\n      <td>https://www.reddit.com/gallery/142j5a1</td>\n      <td>12.00</td>\n      <td>12.0</td>\n      <td>[12]</td>\n      <td>https://preview.redd.it/body-fat-v0-gbp2nkr0ze...</td>\n      <td>https://preview.redd.it/body-fat-v0-k42s9or0ze...</td>\n      <td>https://preview.redd.it/body-fat-v0-bxe5onr0ze...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>970</th>\n      <td>5’7, 20, 143, 13% body fat.</td>\n      <td>https://www.reddit.com/gallery/1fdkwl1</td>\n      <td>20.00</td>\n      <td>20.0</td>\n      <td>[20]</td>\n      <td>https://preview.redd.it/57-20-143-13-body-fat-...</td>\n      <td>https://preview.redd.it/57-20-143-13-body-fat-...</td>\n      <td>https://preview.redd.it/57-20-143-13-body-fat-...</td>\n      <td>https://preview.redd.it/57-20-143-13-body-fat-...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>971</th>\n      <td>5’5 165lbs/74kg what body fat % am i at?</td>\n      <td>https://www.reddit.com/gallery/13rnk8s</td>\n      <td>7.00</td>\n      <td>7.0</td>\n      <td>[6, 8]</td>\n      <td>https://preview.redd.it/55-165lbs-74kg-what-bo...</td>\n      <td>https://preview.redd.it/55-165lbs-74kg-what-bo...</td>\n      <td>https://preview.redd.it/55-165lbs-74kg-what-bo...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>972</th>\n      <td>M19 169.8lbs 6’0 what’s my body fat and do I b...</td>\n      <td>https://i.redd.it/hcbojzwjlmod1.jpeg</td>\n      <td>15.00</td>\n      <td>15.0</td>\n      <td>[15]</td>\n      <td>https://i.redd.it/hcbojzwjlmod1.jpeg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>973</th>\n      <td>What’s my body type or percentage ? I don’t lo...</td>\n      <td>https://www.reddit.com/gallery/zsn760</td>\n      <td>29.67</td>\n      <td>29.0</td>\n      <td>[33, 30, 25, 28, 35, 27]</td>\n      <td>https://preview.redd.it/whats-my-body-type-or-...</td>\n      <td>https://preview.redd.it/whats-my-body-type-or-...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>974 rows × 10 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"First we must downlaod all the images from our dataframe using simple http fetching. The images are stores as row_image_number.filename","metadata":{}},{"cell_type":"code","source":"import requests\nfrom tqdm import tqdm\n\ndef download_all_images(df, output_dir=\"images\"):\n    os.makedirs(output_dir, exist_ok=True)\n    image_cols = [f\"image_{i}\" for i in range(1, 6)]\n    \n    seen_urls = set()\n    image_count = 0\n\n    for idx, row in tqdm(df.iterrows(), total=len(df)):\n        for col in image_cols:\n            url = row.get(col)\n            if isinstance(url, str) and url.startswith(\"http\") and url not in seen_urls:\n                try:\n                    response = requests.get(url, timeout=10)\n                    if response.status_code == 200:\n                        file_ext = url.split('.')[-1].split('?')[0]\n                        file_name = f\"{idx}_{col}.{file_ext}\"\n                        file_path = os.path.join(output_dir, file_name)\n                        with open(file_path, \"wb\") as f:\n                            f.write(response.content)\n                        seen_urls.add(url)\n                        image_count += 1\n                except Exception as e:\n                    print(f\"Error downloading {url}: {e}\")\n\n    print(f\"\\nDownloaded {image_count} unique images to '{output_dir}/'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:18:56.095617Z","iopub.execute_input":"2025-06-09T20:18:56.095877Z","iopub.status.idle":"2025-06-09T20:18:56.211032Z","shell.execute_reply.started":"2025-06-09T20:18:56.095859Z","shell.execute_reply":"2025-06-09T20:18:56.210341Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"This maps our original dataset, where each row could have up to 5 images, into a dataset where each image has it's own row - and a coresponding body fat %. This prepares the data to be put through our model! ","metadata":{}},{"cell_type":"code","source":"def create_regression_csv(df, output_csv=\"image_labels.csv\", label_col=\"meanPrediction\", image_prefix=\"image_\", output_dir=\"images\"):\n    # Ensure column names are stripped of whitespace\n    df.columns = df.columns.str.strip()\n    \n    image_cols = [col for col in df.columns if col.startswith(image_prefix)]\n    records = []\n\n    for idx, row in df.iterrows():\n        label = row[label_col]\n        for col in image_cols:\n            url = row.get(col)\n            if isinstance(url, str) and url.startswith(\"http\"):\n                ext = url.split('.')[-1].split('?')[0].lower()\n                ext = ext if ext in ['jpg', 'jpeg', 'png', 'webp'] else 'jpg'\n                filename = f\"{idx}_{col}.{ext}\"\n                records.append({\"filename\": filename, \"target\": label})\n    \n    df_out = pd.DataFrame(records)\n    df_out.to_csv(output_csv, index=False)\n    print(f\"Created {output_csv} with {len(df_out)} labeled images\")\n    return df_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:18:56.212631Z","iopub.execute_input":"2025-06-09T20:18:56.212928Z","iopub.status.idle":"2025-06-09T20:18:56.218812Z","shell.execute_reply.started":"2025-06-09T20:18:56.212909Z","shell.execute_reply":"2025-06-09T20:18:56.218151Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Download and map!","metadata":{}},{"cell_type":"code","source":"download_all_images(df)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:18:56.219377Z","iopub.execute_input":"2025-06-09T20:18:56.219567Z","iopub.status.idle":"2025-06-09T20:21:44.167599Z","shell.execute_reply.started":"2025-06-09T20:18:56.219552Z","shell.execute_reply":"2025-06-09T20:21:44.166935Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 974/974 [02:47<00:00,  5.80it/s]","output_type":"stream"},{"name":"stdout","text":"\nDownloaded 1977 unique images to 'images/'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df_labels = create_regression_csv(df) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:21:44.168368Z","iopub.execute_input":"2025-06-09T20:21:44.168624Z","iopub.status.idle":"2025-06-09T20:21:44.241449Z","shell.execute_reply.started":"2025-06-09T20:21:44.168599Z","shell.execute_reply":"2025-06-09T20:21:44.240601Z"}},"outputs":[{"name":"stdout","text":"Created image_labels.csv with 2002 labeled images\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"As we can see, our images have downloaded and are stored in a much more simple dataframe!","metadata":{}},{"cell_type":"code","source":"df_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:21:44.242831Z","iopub.execute_input":"2025-06-09T20:21:44.243040Z","iopub.status.idle":"2025-06-09T20:21:44.251275Z","shell.execute_reply.started":"2025-06-09T20:21:44.243024Z","shell.execute_reply":"2025-06-09T20:21:44.250465Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        filename  target\n0  0_image_1.jpg     8.0\n1  0_image_2.jpg     8.0\n2  0_image_3.jpg     8.0\n3  0_image_4.jpg     8.0\n4  1_image_1.jpg     9.8","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0_image_1.jpg</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0_image_2.jpg</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0_image_3.jpg</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0_image_4.jpg</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_image_1.jpg</td>\n      <td>9.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from fastai.vision.all import *\n\nfailed = verify_images(get_image_files(Path('images')))\nfailed.map(Path.unlink)\nlen(failed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:21:44.252153Z","iopub.execute_input":"2025-06-09T20:21:44.252698Z","iopub.status.idle":"2025-06-09T20:22:00.707407Z","shell.execute_reply.started":"2025-06-09T20:21:44.252666Z","shell.execute_reply":"2025-06-09T20:22:00.706357Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"Split training and validation sets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Drop NaNs and build the initial label dictionary\ninitial_nan_labels_count = df_labels['target'].isna().sum()\nif initial_nan_labels_count > 0:\n    print(f\"DEBUG: Found {initial_nan_labels_count} NaN values in 'target' column. Dropping rows with NaN targets.\")\n    df_labels.dropna(subset=['target'], inplace=True)\nelse:\n    print(\"DEBUG: No NaN values found in 'target' column (good).\")\n\n# Split into train and validation\ntrain_df, valid_df = train_test_split(df_labels, test_size=0.2, random_state=42)\n\ntrain_label_dict = dict(zip(train_df['filename'], train_df['target']))\nvalid_label_dict = dict(zip(valid_df['filename'], valid_df['target']))\nall_label_dict = {**train_label_dict, **valid_label_dict}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:42:01.977185Z","iopub.execute_input":"2025-06-09T20:42:01.977488Z","iopub.status.idle":"2025-06-09T20:42:01.988325Z","shell.execute_reply.started":"2025-06-09T20:42:01.977465Z","shell.execute_reply":"2025-06-09T20:42:01.987480Z"}},"outputs":[{"name":"stdout","text":"DEBUG: No NaN values found in 'target' column (good).\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Now lets make the datablock. For augmentations, we'll do all except warp (that might make the phyisquese look too different). We can see some of our datablock's examples with show_batch.","metadata":{}},{"cell_type":"code","source":"print(f\"DEBUG: Train labels: {len(train_label_dict)} | Valid labels: {len(valid_label_dict)}\")\n\n# Get all image files\npath = Path('images')\nprint(f\"DEBUG: Image path set to: {path}\")\n\nall_image_files = get_image_files(path)\nprint(f\"DEBUG: Total image files found by get_image_files: {len(all_image_files)}\")\n\n# Filter image files to only those with matching labels\nprocessable_image_files = [f for f in all_image_files if f.name in all_label_dict]\nprint(f\"DEBUG: Processable image files (with matching labels): {len(processable_image_files)}\")\n\n# Safety check\nif len(processable_image_files) == 0:\n    print(\"CERROR: No processable image files found (no images match labels or vice-versa).\")\n    if all_image_files and all_label_dict:\n        print(f\"  Sample image file: {all_image_files[0].name}\")\n        print(f\"  Sample label key: {next(iter(all_label_dict.keys()))}\")\n        if all_image_files[0].name not in all_label_dict and all_image_files[0].name.split('.')[0] in [k.split('.')[0] for k in all_label_dict.keys()]:\n            print(\" Filename extensions might differ between image files and label keys.\")\n    raise ValueError(\"Cannot create DataLoaders: No matching image files and labels.\")\n\n# Helper function to get label\ndef get_y_func(fn):\n    key = fn.name\n    if key not in all_label_dict:\n        print(f\"DEBUG ERROR: Label not found for: {key} during get_y_func call. This should not happen if pre-filtered.\")\n        raise ValueError(f\"Label not found for: {key}\")\n    return all_label_dict[key]\n\n# Generate index lists for DataBlock IndexSplitter\nfilename_to_index = {f.name: i for i, f in enumerate(processable_image_files)}\nvalid_idxs = [filename_to_index[fname] for fname in valid_df['filename'] if fname in filename_to_index]\nsplitter = IndexSplitter(valid_idxs)\n\ndef convert_to_rgb(img):\n    return img.convert('RGB')\n\n# Transformations\nitem_tfms = Resize(192, method=\"pad\")\n\nbatch_tfms = aug_transforms(\n    do_flip=True,\n    max_rotate=5,     \n    max_zoom=1.05,    \n    max_lighting=0.2, \n    max_warp=0.,\n    p_affine=0.5,     \n    p_lighting=0.5   \n)\ndblock = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_items=lambda _: processable_image_files,\n    splitter=splitter,\n    get_y=get_y_func,\n    item_tfms=item_tfms,\n    batch_tfms=batch_tfms,\n    n_inp=1\n)\n\nprint(\"DEBUG: Attempting to create DataLoaders...\")\ntry:\n    dls = dblock.dataloaders(path, bs=16)\n    print(\"DEBUG: DataLoaders created successfully.\")\n    print(f\"DEBUG: Number of training batches: {len(dls.train)}\")\n    print(f\"DEBUG: Number of validation batches: {len(dls.valid)}\")\nexcept Exception as e:\n    print(f\"CRITICAL ERROR: Failed to create DataLoaders: {e}\")\n    raise\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:42:15.885543Z","iopub.execute_input":"2025-06-09T20:42:15.886103Z","iopub.status.idle":"2025-06-09T20:42:15.963952Z","shell.execute_reply.started":"2025-06-09T20:42:15.886078Z","shell.execute_reply":"2025-06-09T20:42:15.963050Z"}},"outputs":[{"name":"stdout","text":"DEBUG: Train labels: 1601 | Valid labels: 401\nDEBUG: Image path set to: images\nDEBUG: Total image files found by get_image_files: 1988\nDEBUG: Processable image files (with matching labels): 1988\nDEBUG: Attempting to create DataLoaders...\nDEBUG: DataLoaders created successfully.\nDEBUG: Number of training batches: 49\nDEBUG: Number of validation batches: 13\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Train it!","metadata":{}},{"cell_type":"code","source":"import timm\nfrom fastai.vision.all import *\n\n# Create model with correct input size\nmodel = timm.create_model('efficientnet_b3', pretrained=True, num_classes=1)\n\n# Create learner with the pre-configured model\nlearn = Learner(dls, model, metrics=rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:42:34.901448Z","iopub.execute_input":"2025-06-09T20:42:34.901756Z","iopub.status.idle":"2025-06-09T20:42:35.661348Z","shell.execute_reply.started":"2025-06-09T20:42:34.901735Z","shell.execute_reply":"2025-06-09T20:42:35.660520Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d2c22f5775b485ca24a6c1d74f03055"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"import timm\nmodels_192 = [m for m in timm.list_models() if '192' in m]\nprint(models_192)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:28:26.872197Z","iopub.execute_input":"2025-06-09T20:28:26.872486Z","iopub.status.idle":"2025-06-09T20:28:26.881075Z","shell.execute_reply.started":"2025-06-09T20:28:26.872466Z","shell.execute_reply":"2025-06-09T20:28:26.880266Z"}},"outputs":[{"name":"stdout","text":"['levit_192', 'levit_conv_192', 'swinv2_base_window12_192', 'swinv2_base_window12to16_192to256', 'swinv2_base_window12to24_192to384', 'swinv2_large_window12_192', 'swinv2_large_window12to16_192to256', 'swinv2_large_window12to24_192to384']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"learn.fine_tune(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:42:42.576420Z","iopub.execute_input":"2025-06-09T20:42:42.576716Z","iopub.status.idle":"2025-06-09T20:57:01.907884Z","shell.execute_reply.started":"2025-06-09T20:42:42.576694Z","shell.execute_reply":"2025-06-09T20:57:01.906897Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>_rmse</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>77.233795</td>\n      <td>48.626171</td>\n      <td>6.973247</td>\n      <td>00:40</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>_rmse</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>22.911894</td>\n      <td>21.275160</td>\n      <td>4.612501</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>15.904384</td>\n      <td>18.728285</td>\n      <td>4.327619</td>\n      <td>00:41</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>12.096505</td>\n      <td>19.653515</td>\n      <td>4.433228</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>12.782197</td>\n      <td>23.705399</td>\n      <td>4.868819</td>\n      <td>00:41</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>11.900510</td>\n      <td>25.282988</td>\n      <td>5.028219</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>11.680777</td>\n      <td>21.086611</td>\n      <td>4.592016</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>11.523120</td>\n      <td>18.277639</td>\n      <td>4.275236</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>9.310676</td>\n      <td>15.466438</td>\n      <td>3.932740</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>8.404969</td>\n      <td>17.507156</td>\n      <td>4.184155</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>6.968577</td>\n      <td>157.423004</td>\n      <td>12.546833</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>6.089008</td>\n      <td>13.498816</td>\n      <td>3.674074</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>4.906391</td>\n      <td>13.009727</td>\n      <td>3.606900</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>3.750967</td>\n      <td>17.763968</td>\n      <td>4.214732</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>3.338405</td>\n      <td>11.826587</td>\n      <td>3.438981</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.782578</td>\n      <td>11.406363</td>\n      <td>3.377331</td>\n      <td>00:41</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.355499</td>\n      <td>31.284317</td>\n      <td>5.593238</td>\n      <td>00:43</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.934214</td>\n      <td>14.048365</td>\n      <td>3.748115</td>\n      <td>00:42</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.374425</td>\n      <td>13.210714</td>\n      <td>3.634655</td>\n      <td>00:42</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.158095</td>\n      <td>14.907706</td>\n      <td>3.861050</td>\n      <td>00:42</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.115826</td>\n      <td>13.545874</td>\n      <td>3.680472</td>\n      <td>00:43</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"Now we have a working model! For example, it predicts this picture at 13% bodyfat (not so far off in my opinion)","metadata":{}},{"cell_type":"code","source":"bf,_,probs = learn.predict(PILImage.create('images/248_image_2.jpg'))\nprint(f\"Bodyfat prediction: {probs[0]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:22:08.891063Z","iopub.status.idle":"2025-06-09T20:22:08.891382Z","shell.execute_reply.started":"2025-06-09T20:22:08.891202Z","shell.execute_reply":"2025-06-09T20:22:08.891225Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Finally, export the model","metadata":{}},{"cell_type":"code","source":"learn.export('model.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:22:08.892211Z","iopub.status.idle":"2025-06-09T20:22:08.892437Z","shell.execute_reply.started":"2025-06-09T20:22:08.892331Z","shell.execute_reply":"2025-06-09T20:22:08.892341Z"}},"outputs":[],"execution_count":null}]}